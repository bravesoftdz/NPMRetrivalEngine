<!doctype html>
<html class="no-js hasSidebar hasPageActions hasBreadcrumb " lang="en-us" dir="ltr">
 <head> 
  <meta charset="utf-8"> 
  <meta name="viewport" content="width=device-width, initial-scale=1.0"> 
  <meta property="og:title" content="Computer Vision API for Microsoft Cognitive Services"> 
  <meta property="og:image" content="https://docs.microsoft.com/_themes/docs.theme/master/en-us/_themes/images/microsoft-header.png"> 
  <meta name="twitter:card" content="summary"> 
  <meta name="twitter:site" content="@docsmsft"> 
  <meta name="twitter:title" content="Computer Vision API for Microsoft Cognitive Services"> 
  <meta name="twitter:description" content="Use advanced algorithms in the Computer Vision API to help you process images and return information in Microsoft Cognitive Services."> 
  <meta name="twitter:image" content="https://docs.microsoft.com/_themes/docs.theme/master/en-us/_themes/images/microsoft-header.png"> 
  <meta name="twitter:image:alt" content="Microsoft Logo"> 
  <meta name="breadcrumb_path" content="/azure/bread/toc.json"> 
  <meta name="author" content="JuliaNik"> 
  <meta name="description" content="Use advanced algorithms in the Computer Vision API to help you process images and return information in Microsoft Cognitive Services."> 
  <meta name="ms.author" content="juliakuz"> 
  <meta name="manager" content="ytkuo"> 
  <meta name="ms.topic" content="article"> 
  <meta name="services" content="cognitive-services"> 
  <meta name="ms.service" content="cognitive-services"> 
  <meta name="ms.date" content="08/10/2017"> 
  <meta name="ms.technology" content="computer-vision"> 
  <meta name="search.ms_sitename" content="Docs"> 
  <meta name="search.ms_docsetname" content="azure-documents"> 
  <meta name="version" content="0"> 
  <meta name="locale" content="en-us"> 
  <meta name="site_name" content="Docs"> 
  <meta name="search.ms_product" content="Azure"> 
  <meta name="depot_name" content="Azure.azure-documents"> 
  <meta name="updated_at" content="2017-08-10 05:03 PM"> 
  <meta name="gitcommit" content="https://github.com/MicrosoftDocs/azure-docs-pr/blob/7761e16be56b93731a0c9a5d497a466f94533e54/articles/cognitive-services/Computer-vision/Home.md"> 
  <meta name="original_content_git_url" content="https://github.com/MicrosoftDocs/azure-docs-pr/blob/live/articles/cognitive-services/Computer-vision/Home.md"> 
  <meta name="document_id" content="f12a77c5-fc42-c179-5af7-6c7b2197de28"> 
  <meta name="pagetype" content="Conceptual"> 
  <meta name="toc_rel" content="toc.json"> 
  <meta name="pdf_url_template" content="https://docs.microsoft.com/pdfstore/en-us/Azure.azure-documents/{branchName}{pdfName}"> 
  <meta name="word_count" content="1855"> 
  <meta name="scope" content="Azure"> 
  <link href="https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/home" rel="canonical"> 
  <title>Computer Vision API for Microsoft Cognitive Services | Microsoft Docs</title> 
  <link rel="stylesheet" href="/_themes/docs.theme/master/en-us/_themes/css/c30aa829d74693464dd5.site.css "> 
  <link rel="stylesheet" href="/_themes/docs.theme/master/en-us/_themes/css/c30aa829d74693464dd5.conceptual.css "> 
  <link rel="stylesheet" href="/_themes/docs.theme/master/en-us/_themes/global/css/azureHeader.css?v=4"> 
  <link rel="stylesheet" href="https://azure.microsoft.com/en-us/asset/menucss/"> 
  <script>
	var msDocs = {
		data:{
			contentLocale: 'en-us',
			contentDir: 'ltr',
			userLocale: 'en-us',
			userDir: 'ltr',
			pathToTheme: '/_themes/docs.theme/master/en-us/_themes/',
			pageTemplate: 'Conceptual',
			brand: 'azure'
		},
		functions:{},
		settings:{
			extendBreadcrumb: false
		}
	};
	if (!('Promise' in window && 'resolve' in window.Promise && 'reject' in window.Promise && 'all' in window.Promise && 'race' in window.Promise)) {
		document.write('<script src="/_themes/docs.theme/master/en-us/_themes/global/js/bluebird.min.js"><\/script>');
	}
	</script> 
  <!--[if lt IE 9]>
		<script src="https://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.12.4.min.js"></script>
		<script src="/_themes/docs.theme/master/en-us/_themes/global/js/polyfills/all.js"></script>
<script src="/_themes/docs.theme/master/en-us/_themes/global/js/azureHeader/respond_and_ie8Setup_combine.js"></script>	<![endif]--> 
  <!--[if gte IE 9]><!--> 
  <script src="https://ajax.aspnetcdn.com/ajax/jQuery/jquery-2.2.4.min.js"></script> 
  <!--<![endif]--> 
  <script>window.jQuery || document.write('<script src="/_themes/docs.theme/master/en-us/_themes/global/js/jquery/jquery-1.12.4.min.js"><\/script>')</script> 
  <script src="/_themes/docs.theme/master/en-us/_themes/global/js/global.min.js?v=242"></script> 
  <script src="/_themes/docs.theme/master/en-us/_themes/global/js/azureHeader/loader.js?v=4"></script> 
 </head> 
 <body> 
  <div id="lca-cookie-notification" class="container cookieContainer shell-notification-holder" hidden> 
   <div class="shell-notification cookieNotification"> 
    <div class="shell-notification-grid-row shell-notification-clearfix"> 
     <span id="cookie.consent.europe" class="notification-txt">By using this site you agree to the use of cookies for analytics, personalized content and ads.</span> 
     <span class="notification-action"> <a id="privacystatement-link" tabindex="1" href="//privacy.microsoft.com/en-us/privacystatement/" title="Privacy Statement">Learn more</a> <a id="cookie-notification-close" tabindex="2" title="Close"> <i class="shell-icon-close"></i> </a> </span> 
    </div> 
   </div> 
  </div> 
  <div id="headerAreaHolder" class="az_h default" ms.pgarea="header" data-bi-name="header"> 
   <div class="azure-header_holder"> 
    <div class="azure-header"> 
     <header class="azure-header_temp"> 
      <div class="row column"> 
       <a href="https://azure.microsoft.com/en-us/" class="logo" title="Microsoft Azure"> 
        <svg x="0px" y="0px" width="165px" height="20px" viewbox="0 0 165 20"> 
         <path fill="#29A5DE" d="M18,19H16V7.1C16,6.2,16,5,16.1,3.7h0c-0.2,0.8-0.4,1.4-0.5,1.7L9.5,19h-1l-6-13.5c-0.2-0.4-0.3-1-0.5-1.8
							h0C2,4.4,2,5.5,2,7.1V19H0V1.3h2.7l5.4,12.3c0.4,0.9,0.7,1.7,0.8,2.1H9c0.4-1,0.6-1.7,0.9-2.2l5.5-12.3H18V19z" /> 
         <path fill="#29A5DE" d="M22.8,3.1c-0.4,0-0.7-0.1-0.9-0.4s-0.4-0.6-0.4-0.9s0.1-0.7,0.4-0.9c0.3-0.3,0.6-0.4,0.9-0.4
							c0.4,0,0.7,0.1,0.9,0.4c0.3,0.3,0.4,0.6,0.4,0.9c0,0.4-0.1,0.7-0.4,0.9C23.5,3,23.2,3.1,22.8,3.1z M23.8,19h-2V6.3h2V19z" /> 
         <path fill="#29A5DE" d="M35.8,18.4c-1,0.6-2.1,0.9-3.5,0.9c-1.8,0-3.3-0.6-4.4-1.8c-1.1-1.2-1.7-2.7-1.7-4.6c0-2.1,0.6-3.7,1.8-5
							C29.4,6.7,30.9,6,32.9,6C34,6,35,6.2,35.9,6.7v2.1c-0.9-0.7-1.9-1-3-1c-1.3,0-2.3,0.5-3.2,1.4c-0.8,0.9-1.2,2.1-1.2,3.6
							c0,1.5,0.4,2.6,1.2,3.5c0.8,0.9,1.8,1.3,3.1,1.3c1.1,0,2.1-0.4,3.1-1.1V18.4z" /> 
         <path fill="#29A5DE" d="M44.9,8.4C44.5,8.1,44,8,43.3,8c-0.9,0-1.6,0.4-2.2,1.2c-0.6,0.8-0.9,1.9-0.9,3.3V19h-2V6.3h2v2.6h0
							c0.3-0.9,0.7-1.6,1.3-2.1c0.6-0.5,1.3-0.7,2-0.7c0.5,0,0.9,0.1,1.2,0.2V8.4z" /> 
         <path fill="#29A5DE" d="M51.4,19.3c-1.9,0-3.4-0.6-4.5-1.8c-1.1-1.2-1.7-2.7-1.7-4.7c0-2.1,0.6-3.8,1.7-5S49.7,6,51.7,6
							c1.9,0,3.4,0.6,4.4,1.7c1.1,1.2,1.6,2.8,1.6,4.8c0,2-0.6,3.6-1.7,4.8C54.8,18.6,53.3,19.3,51.4,19.3z M51.5,7.7
							c-1.3,0-2.3,0.4-3.1,1.3c-0.8,0.9-1.1,2.1-1.1,3.7c0,1.5,0.4,2.7,1.1,3.5c0.8,0.9,1.8,1.3,3.1,1.3c1.3,0,2.3-0.4,3-1.3
							c0.7-0.8,1.1-2,1.1-3.6c0-1.6-0.4-2.8-1.1-3.6C53.8,8.2,52.8,7.7,51.5,7.7z" /> 
         <path fill="#29A5DE" d="M59.5,18.5v-2.2c1.1,0.8,2.3,1.2,3.6,1.2c1.8,0,2.7-0.6,2.7-1.8c0-0.3-0.1-0.6-0.2-0.9
							c-0.2-0.2-0.4-0.4-0.6-0.6c-0.3-0.2-0.6-0.3-0.9-0.5c-0.3-0.1-0.7-0.3-1.1-0.4c-0.6-0.2-1-0.4-1.5-0.7c-0.4-0.2-0.8-0.5-1.1-0.8
							c-0.3-0.3-0.5-0.6-0.6-1c-0.1-0.4-0.2-0.8-0.2-1.3c0-0.6,0.1-1.1,0.4-1.6C60.2,7.7,60.5,7.3,61,7c0.5-0.3,1-0.5,1.5-0.7
							C63.1,6.1,63.7,6,64.3,6c1.1,0,2.1,0.2,2.9,0.6v2c-0.9-0.6-2-0.9-3.2-0.9c-0.4,0-0.7,0-1,0.1c-0.3,0.1-0.6,0.2-0.8,0.4
							c-0.2,0.2-0.4,0.3-0.5,0.6c-0.1,0.2-0.2,0.5-0.2,0.7c0,0.3,0.1,0.6,0.2,0.8c0.1,0.2,0.3,0.4,0.5,0.6c0.2,0.2,0.5,0.3,0.8,0.5
							c0.3,0.1,0.7,0.3,1.1,0.5c0.6,0.2,1.1,0.4,1.5,0.7c0.4,0.2,0.8,0.5,1.1,0.8c0.3,0.3,0.6,0.6,0.7,1c0.2,0.4,0.3,0.8,0.3,1.3
							c0,0.6-0.1,1.2-0.4,1.6c-0.3,0.5-0.6,0.8-1.1,1.1c-0.5,0.3-1,0.5-1.6,0.7c-0.6,0.1-1.2,0.2-1.9,0.2C61.6,19.3,60.4,19,59.5,18.5z" /> 
         <path fill="#29A5DE" d="M75.6,19.3c-1.9,0-3.4-0.6-4.5-1.8c-1.1-1.2-1.7-2.7-1.7-4.7c0-2.1,0.6-3.8,1.7-5C72.4,6.6,73.9,6,75.9,6
							c1.9,0,3.4,0.6,4.4,1.7c1.1,1.2,1.6,2.8,1.6,4.8c0,2-0.6,3.6-1.7,4.8C79,18.6,77.5,19.3,75.6,19.3z M75.7,7.7
							c-1.3,0-2.3,0.4-3.1,1.3c-0.8,0.9-1.1,2.1-1.1,3.7c0,1.5,0.4,2.7,1.1,3.5c0.8,0.9,1.8,1.3,3.1,1.3c1.3,0,2.3-0.4,3-1.3
							c0.7-0.8,1.1-2,1.1-3.6c0-1.6-0.4-2.8-1.1-3.6C78.1,8.2,77,7.7,75.7,7.7z" /> 
         <path fill="#29A5DE" d="M97.6,8.1V6.3h-3.2V2.6l-2,0.7v3.1h-2.6h-1.5h-1.4V4.4c0-1.8,0.7-2.7,2.1-2.7c0.5,0,0.9,0.1,1.3,0.3V0.2
							C89.9,0.1,89.4,0,88.8,0c-1.1,0-2.1,0.4-2.9,1.2c-0.8,0.8-1.1,1.8-1.1,3.1v2h-2.2v1.7h2.2V19h2V8.1h1.4h1.5h2.6v7.5
							c0,2.5,1.1,3.7,3.3,3.7c0.8,0,1.4-0.1,1.9-0.4v-1.7c-0.4,0.3-0.8,0.4-1.3,0.4c-0.7,0-1.1-0.2-1.4-0.5c-0.3-0.4-0.4-1-0.4-1.8V8.1
							H97.6z" /> 
         <path fill="#29A5DE" d="M119.9,19h-2.3l-1.9-5h-7.5l-1.8,5h-2.3L111,1.3h2.1L119.9,19z M115.1,12.1l-2.8-7.5
							c-0.1-0.2-0.2-0.6-0.3-1.2h0c-0.1,0.5-0.2,0.9-0.3,1.2l-2.7,7.5H115.1z" /> 
         <path fill="#29A5DE" d="M130.4,6.9l-7.5,10.3h7.4V19H120v-0.6l7.5-10.3h-6.8V6.3h9.7V6.9z" /> 
         <path fill="#29A5DE" d="M142.6,19h-2v-2h0c-0.8,1.5-2.1,2.3-3.9,2.3c-3,0-4.5-1.8-4.5-5.4V6.3h2v7.2c0,2.7,1,4,3.1,4
							c1,0,1.8-0.4,2.4-1.1c0.6-0.7,1-1.7,1-2.9V6.3h2V19z" /> 
         <path fill="#29A5DE" d="M152.6,8.4c-0.4-0.3-0.9-0.4-1.5-0.4c-0.9,0-1.6,0.4-2.2,1.2c-0.6,0.8-0.9,1.9-0.9,3.3V19h-2V6.3h2v2.6h0
							c0.3-0.9,0.7-1.6,1.3-2.1c0.6-0.5,1.3-0.7,2-0.7c0.5,0,0.9,0.1,1.2,0.2V8.4z" /> 
         <path fill="#29A5DE" d="M164,13.1h-8.9c0,1.4,0.4,2.5,1.1,3.3c0.7,0.8,1.7,1.1,3,1.1c1.4,0,2.7-0.5,3.9-1.4V18
							c-1.1,0.8-2.6,1.2-4.4,1.2c-1.8,0-3.2-0.6-4.2-1.7c-1-1.1-1.5-2.8-1.5-4.8c0-2,0.6-3.6,1.7-4.8c1.1-1.2,2.5-1.9,4.1-1.9
							s2.9,0.5,3.8,1.6s1.4,2.6,1.4,4.4V13.1z M161.9,11.4c0-1.2-0.3-2.1-0.8-2.7c-0.6-0.6-1.3-1-2.3-1c-1,0-1.8,0.3-2.4,1
							c-0.7,0.7-1.1,1.6-1.2,2.7H161.9z" /> 
        </svg> </a> 
       <a href="#" class="small-search" onclick="return false"><span class="icon icon-search"></span></a> 
      </div> 
     </header> 
    </div> 
   </div> 
  </div> 
  <div class="container mainContainer" lang="en-us" dir="ltr" ms.pgarea="body" data-bi-name="body"> 
   <main role="main" ms.cmpgrp="content" data-bi-name="content"> 
    <div id="main"> 
     <h1 id="computer-vision-api-version-10" sourcefile="articles/cognitive-services/Computer-vision/Home.md" sourcestartlinenumber="15" sourceendlinenumber="15">Computer Vision API Version 1.0</h1> 
     <div class="metadata loading" ms.cmpgrp="page info" data-bi-name="page info"> 
      <div> 
       <time class="date" datetime="8/10/2017 12:00:00 AM">2017-8-10</time> 
       <span class="reading-time">9 min to read</span> 
       <span class="contributors-text">Contributors</span> 
       <ul class="contributors" ms.cmpgrp="contributors" data-bi-name="contributors"> 
        <li><a href="https://github.com/JuliaNik" title="JuliaNik" ms.cmpnm="contributorprofile" data-bi-name="contributorprofile"><img src="https://github.com/JuliaNik.png?size=16" alt="JuliaNik"></a></li> 
        <li><a href="https://github.com/v-royhar" title="Roy Harper" ms.cmpnm="contributorprofile" data-bi-name="contributorprofile"><img src="https://github.com/v-royhar.png?size=16" alt="Roy Harper"></a></li> 
        <li><a href="https://github.com/carolinacmoravia" title="Caro Caserio" ms.cmpnm="contributorprofile" data-bi-name="contributorprofile"><img src="https://github.com/carolinacmoravia.png?size=16" alt="Caro Caserio"></a></li> 
        <li><a href="https://github.com/moeibrahim" title="Moe Ibrahim" ms.cmpnm="contributorprofile" data-bi-name="contributorprofile"><img src="https://github.com/moeibrahim.png?size=16" alt="Moe Ibrahim"></a></li> 
       </ul> 
      </div> 
      <nav id="center-doc-outline" class="doc-outline" ms.cmpgrp="intopic toc" data-bi-name="intopic toc" role="navigation" aria-label="On page navigation"> 
       <h3>In this article</h3> 
      </nav> 
     </div> 
     <div>
      <div class="content"> 
       <p>The cloud-based Computer Vision API provides developers with access to advanced algorithms for processing images and returning information. By uploading an image or specifying an image URL, Microsoft Computer Vision algorithms can analyze visual content in different ways based on inputs and user choices. With the Computer Vision API users can analyze images to:</p> 
       <ul> 
        <li><a href="#Tagging" data-linktype="self-bookmark">Tag images based on content.</a></li> 
        <li><a href="#Categorizing" data-linktype="self-bookmark">Categorize images.</a></li> 
        <li><a href="#Identifying" data-linktype="self-bookmark">Identify the type and quality of images.</a></li> 
        <li><a href="#Faces" data-linktype="self-bookmark">Detect human faces and return their coordinates. </a></li> 
        <li><a href="#Domain-Specific" data-linktype="self-bookmark">Recognize domain-specific content.</a></li> 
        <li><a href="#Descriptions" data-linktype="self-bookmark">Generate descriptions of the content.</a></li> 
        <li><a href="#OCR" data-linktype="self-bookmark">Use optical character recognition to identify printed text found in images.</a></li> 
        <li><a href="#RecognizeText" data-linktype="self-bookmark">Recognize handwritten text.</a></li> 
        <li><a href="#Color" data-linktype="self-bookmark">Distinguish color schemes.</a></li> 
        <li><a href="#Adult" data-linktype="self-bookmark">Flag adult content.</a></li> 
        <li><a href="#Thumbnails" data-linktype="self-bookmark">Crop photos to be used as thumbnails.</a></li> 
       </ul> 
       <h2 id="requirements">Requirements</h2> 
       <ul> 
        <li>Supported input methods: Raw image binary in the form of an application/octet stream or image URL.</li> 
        <li>Supported image formats: JPEG, PNG, GIF, BMP.</li> 
        <li>Image file size: Less than 4 MB.</li> 
        <li>Image dimension: Greater than 50 x 50 pixels.</li> 
       </ul> 
       <h2 id="a-nametaggingtagging-imagesa"><a name="Tagging">Tagging Images</a></h2> 
       <p>Computer Vision API returns tags based on more than 2000 recognizable objects, living beings, scenery, and actions. When tags are ambiguous or not common knowledge, the API response provides 'hints' to clarify the meaning of the tag in context of a known setting. Tags are not organized as a taxonomy and no inheritance hierarchies exist. A collection of content tags forms the foundation for an image 'description' displayed as human readable language formatted in complete sentences. Note, that at this point English is the only supported language for image description.</p> 
       <p>After uploading an image or specifying an image URL, Computer Vision API's algorithms output tags based on the objects, living beings, and actions identified in the image. Tagging is not limited to the main subject, such as a person in the foreground, but also includes the setting (indoor or outdoor), furniture, tools, plants, animals, accessories, gadgets etc.</p> 
       <h3 id="example">Example</h3> 
       <p><img src="images/house_yard.jpg" alt="House_Yard" data-linktype="relative-path"> '</p> 
       <pre><code class="lang-json">Returned Json
{
   'tags':[
      {
         "name":"grass",
         "confidence":0.999999761581421
      },
      {
         "name":"outdoor",
         "confidence":0.999970674514771
      },
      {
         "name":"sky",
         "confidence":999289751052856
      },
      {
         "name":"building",
         "confidence":0.996463239192963
      },
      {
         "name":"house",
         "confidence":0.992798030376434
      },
      {
         "name":"lawn",
         "confidence":0.822680294513702
      },
      {
         "name":"green",
         "confidence":0.641222536563873
      },
      {
         "name":"residential",
         "confidence":0.314032256603241
      },
   ],
}
</code></pre>
       <h2 id="a-namecategorizingcategorizing-imagesa"><a name="Categorizing">Categorizing Images</a></h2> 
       <p>In addition to tagging and descriptions, Computer Vision API returns the taxonomy-based categories defined in previous versions. These categories are organized as a taxonomy with parent/child hereditary hierarchies. All categories are in English. They can be used alone or with our new models.</p> 
       <h3 id="the-86-category-concept">The 86-category concept</h3> 
       <p>Based on a list of 86 concepts seen in the following diagram, visual features found in an image can be categorized ranging from broad to specific. For the full taxonomy in text format, see <a href="https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/category-taxonomy" data-linktype="external">Category Taxonomy</a>.</p> 
       <p><img src="images/analyze_categories.jpg" alt="Analyze Categories" data-linktype="relative-path"></p> 
       <table> 
        <thead> 
         <tr> 
          <th>Image</th> 
          <th>Response</th> 
         </tr> 
        </thead> 
        <tbody> 
         <tr> 
          <td><img src="images/woman_roof.jpg" alt="Woman Roof" data-linktype="relative-path"></td> 
          <td>people</td> 
         </tr> 
         <tr> 
          <td><img src="images/family_photo.jpg" alt="Family Photo" data-linktype="relative-path"></td> 
          <td>people_crowd</td> 
         </tr> 
         <tr> 
          <td><img src="images/cute_dog.jpg" alt="Cute Dog" data-linktype="relative-path"></td> 
          <td>animal_dog</td> 
         </tr> 
         <tr> 
          <td><img src="images/mountain_vista.jpg" alt="Outdoor Mountain" data-linktype="relative-path"></td> 
          <td>outdoor_mountain</td> 
         </tr> 
         <tr> 
          <td><img src="images/bread.jpg" alt="Vision Analyze Food Bread" data-linktype="relative-path"></td> 
          <td>food_bread</td> 
         </tr> 
        </tbody> 
       </table> 
       <h2 id="a-nameidentifyingidentifying-image-typesa"><a name="Identifying">Identifying Image Types</a></h2> 
       <p>There are several ways to categorize images. Computer Vision API can set a boolean flag to indicate whether an image is black and white or color. It can also set a flag to indicate whether an image is a line drawing or not. It can also indicate whether an image is clip art or not and indicate its quality as such on a scale of 0-3.</p> 
       <h3 id="clip-art-type">Clip-art type</h3> 
       <p>Detects whether an image is clip art or not. </p> 
       <table> 
        <thead> 
         <tr> 
          <th>Value</th> 
          <th>Meaning</th> 
         </tr> 
        </thead> 
        <tbody> 
         <tr> 
          <td>0</td> 
          <td>Non-clip-art</td> 
         </tr> 
         <tr> 
          <td>1</td> 
          <td>ambiguous</td> 
         </tr> 
         <tr> 
          <td>2</td> 
          <td>normal-clip-art</td> 
         </tr> 
         <tr> 
          <td>3</td> 
          <td>good-clip-art</td> 
         </tr> 
        </tbody> 
       </table> 
       <table> 
        <thead> 
         <tr> 
          <th>Image</th> 
          <th>Response</th> 
         </tr> 
        </thead> 
        <tbody> 
         <tr> 
          <td><img src="images/cheese_clipart.jpg" alt="Vision Analyze Cheese Clip Art" data-linktype="relative-path"></td> 
          <td>3 good-clip-art</td> 
         </tr> 
         <tr> 
          <td><img src="images/house_yard.jpg" alt="Vision Analyze House Yard" data-linktype="relative-path"></td> 
          <td>0 Non-clip-art</td> 
         </tr> 
        </tbody> 
       </table> 
       <h3 id="line-drawing-type">Line drawing type</h3> 
       <p>Detects whether an image is a line drawing or not. </p> 
       <table> 
        <thead> 
         <tr> 
          <th>Image</th> 
          <th>Response</th> 
         </tr> 
        </thead> 
        <tbody> 
         <tr> 
          <td><img src="images/lion_drawing.jpg" alt="Vision Analyze Lion Drawing" data-linktype="relative-path"></td> 
          <td>True</td> 
         </tr> 
         <tr> 
          <td><img src="images/flower.jpg" alt="Vision Analyze Flower" data-linktype="relative-path"></td> 
          <td>False</td> 
         </tr> 
        </tbody> 
       </table> 
       <h3 id="a-namefacesfacesa"><a name="Faces">Faces</a></h3> 
       <p>Detects human faces within a picture and generates the face coordinates, the rectangle for the face, gender, and age. These visual features are a subset of metadata generated for face. For more extensive metadata generated for faces (facial identification, pose detection, and more), use the Face API. </p> 
       <table> 
        <thead> 
         <tr> 
          <th>Image</th> 
          <th>Response</th> 
         </tr> 
        </thead> 
        <tbody> 
         <tr> 
          <td><img src="images/woman_roof_face.png" alt="Vision Analyze Woman Roof Face" data-linktype="relative-path"></td> 
          <td>[ { "age": 23, "gender": "Female", "faceRectangle": { "left": 1379, "top": 320, "width": 310, "height": 310 } } ]</td> 
         </tr> 
         <tr> 
          <td><img src="images/mom_daughter_face.png" alt="Vision Analyze Mom Daughter Face" data-linktype="relative-path"></td> 
          <td>[ { "age": 28, "gender": "Female", "faceRectangle": { "left": 447, "top": 195, "width": 162, "height": 162 } }, { "age": 10, "gender": "Male", "faceRectangle": { "left": 355, "top": 87, "width": 143, "height": 143 } } ]</td> 
         </tr> 
         <tr> 
          <td><img src="images/family_photo_face.png" alt="Vision Analyze Family Phot Face" data-linktype="relative-path"></td> 
          <td>[ { "age": 11, "gender": "Male", "faceRectangle": { "left": 113, "top": 314, "width": 222, "height": 222 } }, { "age": 11, "gender": "Female", "faceRectangle": { "left": 1200, "top": 632, "width": 215, "height": 215 } }, { "age": 41, "gender": "Male", "faceRectangle": { "left": 514, "top": 223, "width": 205, "height": 205 } }, { "age": 37, "gender": "Female", "faceRectangle": { "left": 1008, "top": 277, "width": 201, "height": 201 } } ]</td> 
         </tr> 
        </tbody> 
       </table> 
       <h2 id="a-namedomain-specificdomain-specific-contenta"><a name="Domain-Specific">Domain-Specific Content</a></h2> 
       <p>In addition to tagging and top-level categorization, Computer Vision API also supports specialized (or domain-specific) information. Specialized information can be implemented as a standalone method or with the high-level categorization. It functions as a means to further refine the 86-category taxonomy through the addition of domain-specific models.</p> 
       <p>Currently, the only specialized information supported are celebrity recognition and landmark recognition. They are domain-specific refinements for the people and people group categories, and landmarks around the world.</p> 
       <p>There are two options for using the domain-specific models:</p> 
       <h3 id="option-one---scoped-analysis">Option One - Scoped Analysis</h3> 
       <p>Analyze only a chosen model, by invoking an HTTP POST call. For this option, if you know which model you want to use, you specify the model's name, and you only get information relevant to that model. For example, you can use this option to only look for celebrity-recognition. The response contains a list of potential matching celebrities, accompanied by their confidence scores.</p> 
       <h3 id="option-two---enhanced-analysis">Option Two - Enhanced Analysis</h3> 
       <p>Analyze to provide additional details related to categories from the 86-category taxonomy. This option is available for use in applications where users want to get generic image analysis in addition to details from one or more domain-specific models. When this method is invoked, the 86-category taxonomy classifier is called first. If any of the categories match that of known/matching models, a second pass of classifier invocations follows. For example, if 'details=all' or "details" include 'celebrities', the method calls the celebrity classifier after the 86-category classifier is called. The result includes tags starting with 'people_'.</p> 
       <h2 id="a-namedescriptionsgenerating-descriptionsa"><a name="Descriptions">Generating Descriptions</a></h2> 
       <p>Computer Vision API's algorithms analyze the content in an image. This analysis forms the foundation for a 'description' displayed as human-readable language in complete sentences. The description summarizes what is found in the image. Computer Vision API's algorithms generate various descriptions based on the objects identified in the image. The descriptions are each evaluated and a confidence score generated. A list is then returned ordered from highest confidence score to lowest. An example of a bot that uses this technology to generate image captions can be found <a href="https://github.com/Microsoft/BotBuilder-Samples/tree/master/CSharp/intelligence-ImageCaption" data-linktype="external">here</a>. </p> 
       <h3 id="example-description-generation">Example Description Generation</h3> 
       <p><img src="images/bw_buildings.jpg" alt="B&amp;W Buildings" data-linktype="relative-path"> '</p> 
       <pre><code class="lang-json"> Returned Json

'description':{
   "captions":[
      {
         "type":"phrase",
         'text':'a black and white photo of a large city',
         'confidence':0.607638706850331
      }
   ]   
   "captions":[
      {
         "type":"phrase",
         'text':'a photo of a large city',
         'confidence':0.577256764264197
      }
   ]   
   "captions":[
      {
         "type":"phrase",
         'text':'a black and white photo of a city',
         'confidence':0.538493271791207
      }
   ]   
   'description':[
      "tags":{
         "outdoor",
         "city",
         "building",
         "photo",
         "large",
      }
   ]
}
</code></pre>
       <h2 id="a-namecolorperceiving-color-schemesa"><a name="Color">Perceiving Color Schemes</a></h2> 
       <p>The Computer Vision algorithm extracts colors from an image. The colors are analyzed in three different contexts: foreground, background, and whole. They are grouped into twelve 12 dominant accent colors. Those accent colors are black, blue, brown, gray, green, orange, pink, purple, red, teal, white, and yellow. Depending on the colors in an image, simple black and white or accent colors may be returned in hexadecimal color codes.</p> 
       <table> 
        <thead> 
         <tr> 
          <th>Image</th> 
          <th>Foreground</th> 
          <th>Background</th> 
          <th>Colors</th> 
         </tr> 
        </thead> 
        <tbody> 
         <tr> 
          <td><img src="images/mountain_vista.jpg" alt="Outdoor Mountain" data-linktype="relative-path"></td> 
          <td>Black</td> 
          <td>Black</td> 
          <td>White</td> 
         </tr> 
         <tr> 
          <td><img src="images/flower.jpg" alt="Vision Analyze Flower" data-linktype="relative-path"></td> 
          <td>Black</td> 
          <td>White</td> 
          <td>White, Black, Green</td> 
         </tr> 
         <tr> 
          <td><img src="images/train_station.jpg" alt="Vision Analyze Train Station" data-linktype="relative-path"></td> 
          <td>Black</td> 
          <td>Black</td> 
          <td>Black</td> 
         </tr> 
        </tbody> 
       </table> 
       <h3 id="accent-color">Accent color</h3> 
       <p>Color extracted from an image designed to represent the most eye-popping color to users via a mix of dominant colors and saturation.</p> 
       <table> 
        <thead> 
         <tr> 
          <th>Image</th> 
          <th>Response</th> 
         </tr> 
        </thead> 
        <tbody> 
         <tr> 
          <td><img src="images/mountain_vista.jpg" alt="Outdoor Mountain" data-linktype="relative-path"></td> 
          <td>#BC6F0F</td> 
         </tr> 
         <tr> 
          <td><img src="images/flower.jpg" alt="Vision Analyze Flower" data-linktype="relative-path"></td> 
          <td>#CAA501</td> 
         </tr> 
         <tr> 
          <td><img src="images/train_station.jpg" alt="Vision Analyze Train Station" data-linktype="relative-path"></td> 
          <td>#484B83</td> 
         </tr> 
        </tbody> 
       </table> 
       <h3 id="black--white">Black &amp; White</h3> 
       <p>Boolean flag that indicates whether an image is black&amp;white or not.</p> 
       <table> 
        <thead> 
         <tr> 
          <th>Image</th> 
          <th>Response</th> 
         </tr> 
        </thead> 
        <tbody> 
         <tr> 
          <td><img src="images/bw_buildings.jpg" alt="Vision Analyze Building" data-linktype="relative-path"></td> 
          <td>True</td> 
         </tr> 
         <tr> 
          <td><img src="images/house_yard.jpg" alt="Vision Analyze House Yard" data-linktype="relative-path"></td> 
          <td>False</td> 
         </tr> 
        </tbody> 
       </table> 
       <h2 id="a-nameadultflagging-adult-contenta"><a name="Adult">Flagging Adult Content</a></h2> 
       <p>Among the various visual categories is the adult and racy group, which enables detection of adult materials and restricts the display of images containing sexual content. The filter for adult and racy content detection can be set on a sliding scale to accommodate the user's preference.</p> 
       <h2 id="a-nameocroptical-character-recognition-ocra"><a name="OCR">Optical Character Recognition (OCR)</a></h2> 
       <p>OCR technology detects text content in an image and extracts the identified text into a machine-readable character stream. You can use the result for search and numerous other purposes like medical records, security, and banking. It automatically detects the language. OCR saves time and provides convenience for users by allowing them to take photos of text instead of transcribing the text.</p> 
       <p>OCR supports 25 languages. These languages are: Arabic, Chinese Simplified, Chinese Traditional, Czech, Danish, Dutch, English, Finnish, French, German, Greek, Hungarian, Italian, Japanese, Korean, Norwegian, Polish, Portuguese, Romanian, Russian, Serbian (Cyrillic and Latin), Slovak, Spanish, Swedish, and Turkish.</p> 
       <p>If needed, OCR corrects the rotation of the recognized text, in degrees, around the horizontal image axis. OCR provides the frame coordinates of each word as seen in below illustration.</p> 
       <p><img src="images/vision-overview-ocr.png" alt="OCR Overview" data-linktype="relative-path"> Requirements for OCR:</p> 
       <ul> 
        <li>The size of the input image must be between 40 x 40 and 3200 x 3200 pixels.</li> 
        <li>The image cannot be bigger than 10 megapixels.</li> 
       </ul> 
       <p>Input image can be rotated by any multiple of 90 degrees plus a small angle of up to '40 degrees.</p> 
       <p>The accuracy of text recognition depends on the quality of the image. An inaccurate reading may be caused by the following situations:</p> 
       <ul> 
        <li>Blurry images.</li> 
        <li>Handwritten or cursive text.</li> 
        <li>Artistic font styles.</li> 
        <li>Small text size.</li> 
        <li>Complex backgrounds, shadows, or glare over text or perspective distortion.</li> 
        <li>Oversized or missing capital letters at the beginnings of words</li> 
        <li>Subscript, superscript, or strikethrough text.</li> 
       </ul> 
       <p>Limitations: On photos where text is dominant, false positives may come from partially recognized words. On some photos, especially photos without any text, precision can vary a lot depending on the type of image.</p> 
       <h2 id="a-namerecognizetextrecognize-handwritten-texta"><a name="RecognizeText">Recognize Handwritten Text</a></h2> 
       <p>This technology allows you to detect and extract handwritten text from notes, letters, essays, whiteboards, forms, etc. It works with different surfaces and backgrounds, such as white paper, yellow sticky notes, and whiteboards.</p> 
       <p>Handwritten text recognition saves time and effort and can make you more productive by allowing you to take images of text, rather than having to transcribe it. It makes it possible to digitize notes. This digitization allows you to implement quick and easy search. It also reduces paper clutter.</p> 
       <p>Input requirements:</p> 
       <ul> 
        <li>Supported image formats: JPEG, PNG, and BMP.</li> 
        <li>Image file size must be less than 4 MB.</li> 
        <li>Image dimensions must be at least 40 x 40, at most 3200 x 3200.</li> 
       </ul> 
       <p>Note: this technology is currently in preview and is only available for English text.</p> 
       <h2 id="a-namethumbnailsgenerating-thumbnailsa"><a name="Thumbnails">Generating Thumbnails</a></h2> 
       <p>A thumbnail is a small representation of a full-size image. Varied devices such as phones, tablets, and PCs create a need for different user experience (UX) layouts and thumbnail sizes. Using smart cropping, this Computer Vision API feature helps solve the problem.</p> 
       <p>After uploading an image, a high-quality thumbnail gets generated and the Computer Vision API algorithm analyzes the objects within the image. It then crops the image to fit the requirements of the 'region of interest' (ROI). The output gets displayed within a special framework as seen in below illustration. The generated thumbnail can be presented using an aspect ration that is different from the aspect ratio of the original image to accommodate a user's needs.</p> 
       <p>The thumbnail algorithm works as follows:</p> 
       <ol> 
        <li>Removes distracting elements from the image and recognizes the main object, the 'region of interest' (ROI).</li> 
        <li>Crops the image based on the identified region of interest.</li> 
        <li>Changes the aspect ratio to fit the target thumbnail dimensions.</li> 
       </ol> 
       <p><img src="images/thumbnail-demo.png" alt="Thumbnails" data-linktype="relative-path"></p> 
      </div>
     </div> 
     <div id="comments-container" ms.cmpgrp="comments" data-bi-name="comments" role="form"></div> 
    </div> 
   </main> 
   <div class="pageActions"> 
    <div id="page-actions" ms.cmpgrp="pageactions" data-bi-name="pageactions" role="complementary"> 
     <div id="page-actions-content"> 
      <ul class="action-list"> 
       <li> <a href="#comments-container" id="comments-link" ms.cmpnm="comments" data-bi-name="comments"> <i class="icon icon-comments"></i>Comments </a> </li> 
       <li id="contenteditbtn"> <a href="https://github.com/Microsoft/azure-docs/blob/master/articles/cognitive-services/Computer-vision/Home.md" title="Edit This Document" ms.cmpnm="edit" data-bi-name="edit"> <i class="icon icon-editor"></i>Edit </a> </li> 
       <li> <a href="#" class="sharebutton" title="Share This Document" ms.cmpnm="share" data-bi-name="share"><i class="icon icon-share"></i>Share</a> 
        <div class="share-container"> 
         <div>
          <a href="" class="share-twitter" ms.cmpnm="twitter" data-bi-name="twitter"><i class="icon icon-twitter"></i>Twitter</a>
         </div> 
         <div>
          <a href="" class="share-linkedin" ms.cmpnm="share-linkedin" data-bi-name="linkedin"><i class="icon icon-linkedin"></i>LinkedIn</a>
         </div> 
         <div>
          <a href="" class="share-facebook" ms.cmpnm="facebook" data-bi-name="facebook"><i class="icon icon-facebook"></i>Facebook</a>
         </div> 
         <div>
          <a href="" class="share-email" ms.cmpnm="email" data-bi-name="email"><i class="icon icon-email"></i>Email</a>
         </div> 
        </div> </li> 
       <li class="typeSep">|</li> 
       <li> <label for="theme-selector">Theme</label> <select id="theme-selector" data-bi-name="select-theme"> <option value="" class="removedOnload"></option> <option value="">Light</option> <option value="theme_night">Dark</option> </select> </li> 
      </ul> 
      <nav id="side-doc-outline" class="doc-outline" ms.cmpnm="intopic toc" data-bi-name="intopic toc" role="navigation" aria-label="On page navigation"> 
       <h3>In this article</h3> 
      </nav> 
     </div> 
    </div> 
   </div> 
   <ul class="breadcrumbs" ms.cmpgrp="breadcrumb" data-bi-name="breadcrumb" role="navigation" aria-label="breadcrumb">
    <li></li>
   </ul> 
   <div class="sidebar" id="sidebar" ms.cmpgrp="left toc" data-bi-name="left toc" role="navigation" aria-label="main navigation" lang="en-us" dir="ltr"> 
    <div id="sidebarContent"> 
     <div class="filterHolder"> 
     </div> 
     <nav class="toc"></nav> 
     <div class="pdfDownloadHolder"></div> 
    </div> 
    <div class="tocSpace"></div> 
   </div> 
   <div id="menu-nav" class="dropdown-container" lang="en-us" dir="ltr"> 
    <div class="dropdown dropdown-full mobilenavi"> 
     <select> </select> 
    </div> 
   </div> 
  </div> 
  <div id="openFeedbackContainer" class="openfeedback-container footer-layout"></div> 
  <div class="container footerContainer"> 
   <footer id="footer" ms.pgarea="footer" data-bi-name="footer" class="footer-layout"> 
    <div class="container" role="contentinfo"> 
     <a id="locale-selector-link" href="#" data-bi-name="select-locale" ms.cmpnm="select-locale"></a> 
     <ul class="links" ms.cmpgrp="footerlinks" data-bi-name="footerlinks"> 
      <li><a id="footer-about-link" href="https://docs.microsoft.com/teamblog" ms.cmpnm="bloglink" data-bi-name="bloglink">Blog</a></li> 
      <li><a id="footer-privacy-link" href="//privacy.microsoft.com/en-us/" ms.cmpnm="privacy" data-bi-name="privacy">Privacy &amp; Cookies</a></li> 
      <li><a id="footer-term-of-use" href="/en-us/legal/termsofuse" ms.cmpnm="termsofuse" data-bi-name="termsofuse">Terms of Use</a></li> 
      <li><a href="//aka.ms/sitefeedback" ms.cmpnm="feedback" data-bi-name="feedback">Feedback</a></li> 
      <li id="impressum-section" hidden><a id="impressum-link" href="#" ms.cmpnm="impressum" data-bi-name="impressum">Impressum</a></li> 
      <li><a href="https://www.microsoft.com/en-us/legal/intellectualproperty/Trademarks/EN-US.aspx" ms.cmpnm="trademarks" data-bi-name="trademarks">Trademarks</a></li> 
     </ul> 
    </div> 
   </footer> 
  </div> 
  <script src="/_themes/docs.theme/master/en-us/_themes/javascript/c30aa829d74693464dd5.conceptual.js"></script>  
 </body>
</html>