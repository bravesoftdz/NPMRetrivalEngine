<!doctype html>
<html>
 <head> 
  <meta http-equiv="content-type" content="text/html; charset=utf-8"> 
  <title>Black-Box Optimization Competition</title> 
  <meta name="keywords" content="Black-Box Optimization Competition BBComp"> 
  <link rel="stylesheet" type="text/css" href="bbcomp.css"> 
  <meta name="robots" content="all"> 
 </head> 
 <body> 
  <div id="main"> 
   <div id="headings"> 
    <div id="heading1" class="stretch">
     Black Box Optimization Competition
    </div> 
    <div id="heading2" class="stretch">
     BBComp
    </div> 
   </div> 
   <div id="logo">
    <img width="200" height="190" src="bbcomp-logo.png">
   </div> 
   <div id="boxes"> 
    <div id="menu" class="darkbox"> 
     <h2 class="bright">Contents</h2> 
     <ul> 
      <li><a href="#background">Background</a></li> 
      <li><a href="#goalsandscope">Goals and Scope</a></li> 
      <li><a href="#howtoparticipate">How to Participate</a></li> 
      <li><a href="#competitionrules">Competition Rules</a></li> 
      <li><a href="#dates">Important Dates</a></li> 
      <li><a href="#evaluation">Evaluation Criteria</a></li> 
      <li><a href="#problems">Problem Statistics</a></li> 
      <li><a href="#downloads">Downloads</a></li> 
      <li><a href="#results">Results</a></li> 
      <li><a href="documentation.html">Documentation</a></li> 
      <li><a href="faq.html">Frequently Asked Questions</a></li> 
      <li><a href="#related">Related Material</a></li> 
     </ul> 
    </div> 
    <div id="login" class="darkbox"> 
     <h2 class="bright">Login*</h2> 
     <form method="POST" action="/login"> 
      <table> 
       <tbody>
        <tr> 
         <td>username&nbsp;&nbsp;</td> 
         <td><input name="username" type="text"></td> 
        </tr> 
        <tr> 
         <td>password&nbsp;&nbsp;</td> 
         <td><input name="password" type="password"></td> 
        </tr> 
        <tr> 
         <td></td> 
         <td><input type="submit" value="login"></td> 
        </tr> 
       </tbody>
      </table> 
     </form> 
    </div> 
    <div id="login" class="requestbox">
      * Please write an email to 
     <a href="mailto:blackboxcompetition@gmail.com">blackboxcompetition@gmail.com</a> to register an account. Check the section 
     <a href="#howtoparticipate">How to Participate</a>. 
    </div> 
   </div> 
   <div id="content" class="clear"> 
    <div class="newsbox"> 
     <h2>For the Impatient</h2> 
     <p> <b>What is BBComp?</b><br> BBComp — the black box optimization competition — is the first competition in continuous black-box optimization where test problems are truly black boxes for participants. It is also the first web/online optimization competition in the direct search domain. </p> Quick links: 
     <a href="#downloads">[Downloads]</a>&nbsp;
     <a href="#competitionrules">[Rules]</a>&nbsp;
     <a href="faq.html">[FAQ]</a>&nbsp;
     <a href="documentation.html">[Documentation]</a>&nbsp;
     <a href="#results">[Results]</a> 
    </div> 
    <div class="newsbox"> 
     <h2>News</h2> 
     <p> <i>July 19, 2017</i>. The <a href="#results">results</a> of all five GECCO'2017 tracks were announced at the conference. </p> 
     <p> <i>June 27, 2017</i>. The deadline for all five GECCO'2017 tracks has been extended by 11 days to <b>July 11, 2017</b>. </p> 
     <p> <i>May 1st, 2017</i>. Five new track open! The tracks resemble last year's competition: we have two single-objective tracks and three multi-objective tracks consisting of "normal" and "expensive" problems. The deadline is first of July. The results will be presented at the <a target="_blank" href="http://gecco-2017.sigevo.org/">GECCO'2017</a> conference. As usual, there is no obligation for participants to attend the conference. We also have published released 1.3.0 of the competition software. The library size was reduced significantly, and the example clients were reorganized. </p> 
    </div> 
    <a name="background"></a> 
    <h2>Background</h2> 
    <p> "Black Box" optimization refers to a problem setup in which an optimization algorithm is supposed to optimize (e.g., minimize) an objective function through a so-called black-box interface: the algorithm may query the value <b>f(x)</b> for a point <b>x</b>, but it does not obtain gradient information, and in particular it cannot make any assumptions on the analytic form of <b>f</b> (e.g., being linear or quadratic). We think of such an objective function as being wrapped in a black-box. The goal of optimization is to find an as good as possible value <b>f(x)</b> within a predefined time, often defined by the number of available queries to the black box. Problems of this type regularly appear in practice, e.g., when optimizing parameters of a model that is either in fact hidden in a black box (e.g., a third party software library) or just too complex to be modeled explicitly. </p> 
    <p> If you are wondering about the <a target="_blank" href="https://en.wikipedia.org/wiki/No_free_lunch_in_search_and_optimization">No Free Lunch Theorem</a> in this context then please read <a target="_blank" href="faq.html#q20">the FAQ</a>. </p> 
    <p> A large variety of optimization algorithms for continuous black box optimization has been proposed. The power of these algorithm is usually assessed on collections of benchmark problems. This is an important approach to comparability of scientific results. However, it means that the problem to be optimized is known to the experimenter, and hence it is not truly a black box. </p> 
    <a name="goalsandscope"></a> 
    <h2>Goals and Scope</h2> 
    <p> The <b>black box optimization competition</b> aims to close this gap by providing an algorithm testbed that is truly a black box to participants. Our testbed consists of a wide range of benchmark problems. The only information known to the optimizer is the dimension of the problem, bounds on all variables, and a budget of black box queries. </p> 
    <p> In this competition – just like in the real wold – there is no second chance! You do not get to try a second method if you fail. However, you are of course free to use your budget in any way, which includes the possibility of reserving a certain fraction of the budget for algorithm selection and parameter tuning. We also regard the optimization procedure as a black box; feel free to do whatever you think works best in a proper black box optimization setting. </p> 
    <p> The competition goals differ from those of established testbeds for black box optimization algorithms (see the <a href="#related">related material</a>). We do not take the perspective of comparing algorithms. Such a comparison will come out as a side effect in the end. However, this would mean that each participant could throw a large number of entries into the ring and see which performs best. Here we allow for only a single entry per participant. This shifts the focus from a comparison of algorithms to a competition of participants. </p> 
    <a name="howtoparticipate"></a> 
    <h2>How to Participate</h2> 
    <p> We provide software for evaluating black box functions from a predefined set of benchmark problems. The software makes sure that the predefined budget of evaluations is not exceeded. </p> 
    <p> Interfacing this software is easy. Example code is provided for C/C++, Java, Python and Matlab. We strongly recommend to <a target="_blank" href="documentation.html">rtfm</a>. </p> 
    <p> The software requires an internet connection with access to the competition server (this very machine that also delivered this web page to your browser). Moreover a personalized account is required, which can be requested by writing an email to <a href="mailto:blackboxcompetition@gmail.com">blackboxcompetition@gmail.com</a>. The account is needed for the competition, but software can be tested beforehand without creating an account. </p> 
    <p> In the spirit of open and reproducible research the organizers appreciate if participants provide their optimization software, e.g., as open source. <b>However, this is no prerequisite for participation!</b> Closed-source algorithms are explicitly allowed. Participants do no need to submit or publish their optimization software or its source code. In the 2015 and 2016 organized within the CEC and GECCO conferences, participants do not need to write a paper. </p> 
    <p> It is possible to participate anonymously in the competition. There is a "public name" field in the account data. Participants may enter their real name (or research group, as appropriate), but they are also free to enter a pseudonym. Only the public name and the method short description (if any) will be published together with the results after the end of the competition. </p> 
    <a name="competitionrules"></a> 
    <h2>Competition Rules</h2> 
    <p> The rules are simple. For each of the problems defined in a competition track, each participant can use any optimization method (including manual and interactive methods) to find a point <b>x</b> with as good as possible value <b>f(x)</b> within a predefined budget of black box queries. The queries are to be conducted through the binary dynamic library found in the <a href="#downloads">downloads section</a>. </p> 
    <p> It is against the rules of the competition to disassemble or otherwise reverse engineer the provided binary software libraries and to intercept or modify their network connections. It is against the rules to gain access to the competition server – this is even against the law. </p> 
    <p> Note: Each participant has only <b>one single attempt</b>. Please make double sure that your software works correctly before starting the actual competition runs. We provide "trial" tracks for software testing and debugging. </p> 
    <a name="dates"></a> 
    <h2>Important dates</h2> 
    <p> 
     <!--
<table style="color: #888;">
<tr><th>01.12.2014&nbsp;&nbsp;&nbsp;</th><td>The software and the &quot;trial&quot; track are available.</td></tr>
<tr><th>01.01.2015&nbsp;&nbsp;&nbsp;</th><td>The competition opens, the CEC'2015 track is available.</td></tr>
<tr><th>01.03.2015&nbsp;&nbsp;&nbsp;</th><td>The competition GECCO'2015 track (expensive setting) is available.</td></tr>
<tr><th>30.04.2015&nbsp;&nbsp;&nbsp;</th><td>The CEC'2015 competition is closed at midnight UCT.</td></tr>
<tr><th>25.05.2015&nbsp;&nbsp;&nbsp;</th><td>Announcement of the results during the CEC'2015.</td></tr>
<tr><th>08.07.2015&nbsp;&nbsp;&nbsp;</th><td>The GECCO'2015 competition is closed at midnight UCT.</td></tr>
<tr><th>15.07.2015&nbsp;&nbsp;&nbsp;</th><td>Announcement of the results during the GECCO'2015.</td></tr>
<tr><th>17.02.2016&nbsp;&nbsp;&nbsp;</th><td>Version 1.1.0 of the software and the &quot;trialMO&quot; track are available.</td></tr>
<tr><th>01.03.2016&nbsp;&nbsp;&nbsp;</th><td>Four new track open, single-objective and multi-objective, &quot;normal&quot; and &quot;expensive&quot;.</td></tr>
<tr><th>30.06.2016&nbsp;&nbsp;&nbsp;</th><td>The four tracks close at midnight UTC.</td></tr>
<tr><th>20.07.2016&nbsp;&nbsp;&nbsp;</th><td>Announcement of the results at <a target="_blank" href="http://gecco-2016.sigevo.org/index.html/Competitions">GECCO'2016</a>.</td></tr>
<tr><th>20.03.2017&nbsp;&nbsp;&nbsp;</th><td>Announcement of the results at EMO'2017.</td></tr>
<tr><th>16.01.2017&nbsp;&nbsp;&nbsp;</th><td>Version 1.2.0 of the software and the &quot;real-world&quot; track for EMO'2017 are available.</td></tr>
<tr><th>15.03.2017&nbsp;&nbsp;&nbsp;</th><td>&quot;Real-world&quot; problems track and GVGPC track close at midnight UTC.</td></tr>
<tr><th>20.03.2017&nbsp;&nbsp;&nbsp;</th><td>Announcement of the results at <a target="_blank" href="http://www.emo2017.org/">EMO'2017</a>.</td></tr>
<tr><th>01.05.2017&nbsp;&nbsp;&nbsp;</th><td>The GECCO'2017 competition track open.</td></tr>
<tr><th>11.07.2017&nbsp;&nbsp;&nbsp;</th><td>The GECCO'2017 competition track close at midnight UTC.</td></tr>
</table>
--> </p>
    <table> 
     <tbody>
      <tr>
       <th>15-19.07.2017&nbsp;&nbsp;&nbsp;</th>
       <td>The results are announced during the GECCO'2017 conference.</td>
      </tr> 
     </tbody>
    </table> 
    <p></p> 
    <a name="evaluation"></a> 
    <h2>Evaluation criteria</h2> 
    <div class="figure">
      Figure: Hypervolume dominated by a finite set for two and three objectives.
     <br> 
     <img src="hypervolume-2D.png">
     <br> 
     <img src="hypervolume-3D.png"> 
    </div> 
    <p> <b>Performance Definition&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b> We unify the evaluation of single-objective and multi-objective optimization problems by first defining a notion of performance. The goal of all single-objective problems is to find an as small as possible function value within the given budget. Hence the performance measure is the smallest function value. For multi-objective optimization the goal is to dominate as much of the objective space as possible, where all objectives are to be minimized. Hence performance is measured by the dominated hypervolume, which must be maximized. To stay compatible with the minimization perspective of the single-objective case, we define multi-objective performance as <b>1 - HV</b>, where <b>HV</b> is the dominated hypervolume (for multi-objective optimization all objective values are guaranteed to be in the unit interval, and we chose the vector of all ones as the reference point for the computation of the hypervolume). The above definition yields a performance value for each participant on each problem. </p> 
    <p> <b>Overall Ranking&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b> The aggregation of performance over all problems in a track is analog to the formula one scoring system. In this analogy each participant corresponds to a driver and each benchmark problem of the competition track corresponds to a race track. For each problem participants are sorted w.r.t. performance and the top scorers receive points depending on their rank. The sum of these points over all problems is the overall score. Participants are ranked w.r.t. this overall score. </p> 
    <p> <b>Tie Breaking&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</b> For some (rather easy) problems we expect multiple participants to achieve near-optimal and hence extremely close results. In this situation purely numerical differences–possibly even depending on programming language and compiler–can decide upon the lion's share of the points (distributed among the top ranks). Hence the ranking procedure is slightly modified as follows: Let <b>ƒ<sup>*</sup></b> denote the best overall performance achieved for a problem. Based on this value a numerical imprecision range is defined as <b>? = max(10<sup>-14</sup>&nbsp;•&nbsp;ƒ<sup>*</sup>,&nbsp;10<sup>-20</sup>)</b>. All algorithms with performance values better than <b>ƒ<sup>*</sup>&nbsp;+&nbsp;?</b> share the first rank, while all worse algorithms are ranked according to their exact performance. </p> 
    <p> Alternative assessment procedures will be considered as well, however, their results will not affect the selection of the winners. </p> 
    <!--
<a name="prize"></a>
<h2>Prize</h2>
<p>
The best three algorithms of the CEC'2015 track will receive <b>500 EUR</b> in total.
</p>
<p>
The best three algorithms of the GECCO'2015 track will receive <b>1000 EUR</b> in total  
<b>sponsored by <a href="http://www.msr-inria.fr/">Microsoft Research - Inria joint centre</a> </b>.
</p>
--> 
    <a name="problems"></a> 
    <h2>Problem Statistics</h2> 
    <p> This section summarizes properties of the optimization problems in different tracks. The values are for reference, the same information can be obtained from the software interface. </p> 
    <p> </p>
    <table class="problems"> 
     <tbody>
      <tr> 
       <th>track name</th> 
       <th>dimensions / number of objectives</th> 
       <th>problems per dimension</th> 
       <th>total number of problems</th> 
       <th>budget</th> 
      </tr> 
      <tr> 
       <td>trial</td> 
       <td>2, 4, 5, 8, 10, 16, 20, 32, 40, 64</td> 
       <td>100</td> 
       <td>1000</td> 
       <td>100&nbsp;<i>dim</i><sup>2</sup></td> 
      </tr> 
      <tr> 
       <td>trialMO</td> 
       <td>2, 4, 5, 8, 10, 16, 20, 32, 40, 64 / 2, 3</td> 
       <td>50</td> 
       <td>1000</td> 
       <td>1000&nbsp;<i>dim</i></td> 
      </tr> 
      <tr> 
       <td>BBComp2015CEC</td> 
       <td>2, 4, 5, 8, 10, 16, 20, 32, 40, 64</td> 
       <td>100</td> 
       <td>1000</td> 
       <td>100&nbsp;<i>dim</i><sup>2</sup></td> 
      </tr> 
      <tr> 
       <td>BBComp2015GECCO</td> 
       <td>2, 4, 5, 8, 10, 16, 20, 32, 40, 64</td> 
       <td>100</td> 
       <td>1000</td> 
       <td>10&nbsp;<i>dim</i> – 100&nbsp;<i>dim</i></td> 
      </tr> 
      <tr> 
       <td>BBComp2016-1OBJ</td> 
       <td>2, 4, 5, 8, 10, 16, 20, 32, 40, 64</td> 
       <td>100</td> 
       <td>1000</td> 
       <td>100&nbsp;<i>dim</i><sup>2</sup></td> 
      </tr> 
      <tr> 
       <td>BBComp2016-1OBJ-expensive</td> 
       <td>2, 4, 5, 8, 10, 16, 20, 32, 40, 64</td> 
       <td>100</td> 
       <td>1000</td> 
       <td>10&nbsp;<i>dim</i> – 100&nbsp;<i>dim</i></td> 
      </tr> 
      <tr> 
       <td>BBComp2016-2OBJ</td> 
       <td>2, 4, 5, 8, 10, 16, 20, 32, 40, 64 / 2</td> 
       <td>100</td> 
       <td>1000</td> 
       <td>1000&nbsp;<i>dim</i></td> 
      </tr> 
      <tr> 
       <td>BBComp2016-2OBJ-expensive</td> 
       <td>2, 4, 5, 8, 10, 16, 20, 32, 40, 64 / 2</td> 
       <td>100</td> 
       <td>1000</td> 
       <td>10&nbsp;<i>dim</i> – 100&nbsp;<i>dim</i></td> 
      </tr> 
      <tr> 
       <td>BBComp2016-3OBJ</td> 
       <td>2, 4, 5, 8, 10, 16, 20, 32, 40, 64 / 3</td> 
       <td>100</td> 
       <td>1000</td> 
       <td>1000&nbsp;<i>dim</i></td> 
      </tr> 
      <tr> 
       <td>BBComp2017-1OBJ</td> 
       <td>2, 4, 5, 8, 10, 16, 20, 32, 40, 64</td> 
       <td>100</td> 
       <td>1000</td> 
       <td>100&nbsp;<i>dim</i><sup>2</sup></td> 
      </tr> 
      <tr> 
       <td>BBComp2017-1OBJ-expensive</td> 
       <td>2, 4, 5, 8, 10, 16, 20, 32, 40, 64</td> 
       <td>100</td> 
       <td>1000</td> 
       <td>10&nbsp;<i>dim</i> – 100&nbsp;<i>dim</i></td> 
      </tr> 
      <tr> 
       <td>BBComp2017-2OBJ</td> 
       <td>2, 4, 5, 8, 10, 16, 20, 32, 40, 64 / 2</td> 
       <td>100</td> 
       <td>1000</td> 
       <td>1000&nbsp;<i>dim</i></td> 
      </tr> 
      <tr> 
       <td>BBComp2017-2OBJ-expensive</td> 
       <td>2, 4, 5, 8, 10, 16, 20, 32, 40, 64 / 2</td> 
       <td>100</td> 
       <td>1000</td> 
       <td>10&nbsp;<i>dim</i> – 100&nbsp;<i>dim</i></td> 
      </tr> 
      <tr> 
       <td>BBComp2017-3OBJ</td> 
       <td>2, 4, 5, 8, 10, 16, 20, 32, 40, 64 / 3</td> 
       <td>100</td> 
       <td>1000</td> 
       <td>1000&nbsp;<i>dim</i></td> 
      </tr> 
     </tbody>
    </table> 
    <p></p> 
    <p> All functions are deterministic (noise free). Querying a point twice yields the exact same function value. </p> 
    <a name="realworld"></a> 
    <h2>EMO'2017 Real-World Problems</h2> 
    <p> The EMO'2017 track (BBComp2017EMO) consists of 10 challenging real-world problems from various domains, listed below. We thank Michael Emmerich for co-chairing this track. The deadline for the track is at midnight UCT on March 14/15, 2017. </p> 
    <p> </p>
    <table class="problems"> 
     <tbody>
      <tr> 
       <th>problem index</th> 
       <th>problem name</th> 
       <th>dimensions</th> 
       <th>number of objectives</th> 
       <th>budget</th> 
      </tr> 
      <tr> 
       <td>0</td> 
       <td>welded beam</td> 
       <td>4</td> 
       <td>2</td> 
       <td>100</td> 
      </tr> 
      <tr> 
       <td>1</td> 
       <td>kernel ridge regression</td> 
       <td>5</td> 
       <td>2</td> 
       <td>100</td> 
      </tr> 
      <tr> 
       <td>2</td> 
       <td>brake</td> 
       <td>4</td> 
       <td>2</td> 
       <td>100</td> 
      </tr> 
      <tr> 
       <td>3</td> 
       <td>facility placement</td> 
       <td>20</td> 
       <td>2</td> 
       <td>1000</td> 
      </tr> 
      <tr> 
       <td>4</td> 
       <td>hydro-dynamics</td> 
       <td>6</td> 
       <td>2</td> 
       <td>1000</td> 
      </tr> 
      <tr> 
       <td>5</td> 
       <td>heat exchanger</td> 
       <td>16</td> 
       <td>2</td> 
       <td>500</td> 
      </tr> 
      <tr> 
       <td>6</td> 
       <td>neural network controller</td> 
       <td>24</td> 
       <td>2</td> 
       <td>2000</td> 
      </tr> 
      <tr> 
       <td>7</td> 
       <td>optical filter</td> 
       <td>11</td> 
       <td>2</td> 
       <td>200</td> 
      </tr> 
      <tr> 
       <td>8</td> 
       <td>area under curve</td> 
       <td>10</td> 
       <td>2</td> 
       <td>500</td> 
      </tr> 
      <tr> 
       <td>9</td> 
       <td>vibrating platform</td> 
       <td>5</td> 
       <td>2</td> 
       <td>200</td> 
      </tr> 
     </tbody>
    </table> 
    <p></p> 
    <p> The problem names reflect the underlying problems without giving any details. Beyond the provided problem names, no further information on the problems or their encoding will be provided before the end of the EMO'2017 competition, in order to maintain the black-box character of the competition. We plan to publish the problems after the deadline. </p> 
    <!--
<a name="GVGPC"></a>
<h2>EMO'2017 General Video Game Playing Competition</h2>
<p>
The goal of the track (GVGPC2017EMO) is to parameterize a generic
controller (based on Monte Carlo tree search) to play multiple games at
once. The track consists of three problems, defined by three games each.
The track is organized by Ahmed Abdel Samea Khalifa, Mike Preu&szlig;
and Julian Togelius. It is based on the
<a target="_blank" href="http://www.gvgai.net/">General Video Game Playing</a>
software framework.
</p>
<p>
<table class="problems">
<tr>
	<th>track name</th>
	<th>dimensions / number of objectives</th>
	<th>problems per dimension</th>
	<th>total number of problems</th>
	<th>budget</th>
</tr>
<tr>
	<td>GVGPC2017EMO</td>
	<td>14 / 3</td>
	<td>3</td>
	<td>3</td>
	<td>1000</td>
</tr>
</table>
</p>
<p>
The deadline for the track is at midnight UCT on March 14/15, 2017.
For all three problems, the input space dimension is 14 (number of
controller parameters), the number of objectives (games) is three, and
the available budget of black box queries is 1000.
</p>
<p>
NOTE: In contrast to all other BBComp track, due to the randomized
nature of Monte Carlo tree search, the objective functions of this track
are non-deterministic. I.e., evaluating the same parameter configuration
twice will result in different objective vectors.
</p>
<p>
This track requires additional software, namely the file
GVGPC-2017-EMO.zip available from the downloads section below. Please
follow the instructions in the readme file contained in the archive. In
short: extract the archive, make the environment variable GVGPCPATH
point to the directory GVGPC-2017-EMO, and make sure to use the most
recent version of the BBComp software (version 1.2 or later). If the
files are not found or the execution fails then the library returns the
generic error message &quot;unhandled error during evaluate&quot;.
</p>
<p>
As usual in BBComp,
<a href="faq.html#q14">software should be tested carefully</a> before
running the actual competition. The three-objective problems in the
trialMO track should be used for this purpose. Please refer to the
<a target="_blank" href="documentation.html">documentation</a>
and the <a target="_blank" href="faq.html">FAQ</a> for details.
</p>
--> 
    <a name="downloads"></a> 
    <h2>Downloads</h2> 
    <p> We provide software packages for Windows, Linux, and MacOS for download. The core of each of these packages is a dynamic library. This library acts as the black box. </p> 
    <p> The dynamic library can be accessed directly from C and from C++. For convenience we also provide pre-built interfaces for Matlab, Python, and Java. We appreciate contributions for further programming languages. </p> 
    <p> The BBComp client software comes with the following <a target="_blank" href="license.html">license</a>. The current version of the software is 1.2.0. </p> 
    <div id="downloadtable"> 
     <table> 
      <tbody>
       <tr>
        <td> 
         <!--
<h3 class="bright">Windows 32bit</h3>
Black Box competition module for Windows.
The software has been tested on Windows Vista, 7, 8.
</td><td width="300">
<a href="downloads/bbcomp-windows-32bit.zip">bbcomp-windows-32bit.zip</a>
</td></tr>
<tr><td>
--> <h3 class="bright">Windows 64bit</h3> Black Box competition module for Windows. <p> <b>NOTE:</b> Windows&nbsp;7 users may have to install version 14 of the MSVC runtime libraries, see e.g. <a target="_blank" href="http://stackoverflow.com/questions/33265663/api-ms-win-crt-runtime-l1-1-0-dll-is-missing-when-opening-microsoft-office-file">this post</a>. </p> </td>
        <td width="300"> <a href="downloads/bbcomp-windows-64bit.zip">bbcomp-windows-64bit.zip</a> </td>
       </tr> 
       <!--
<tr><td>
<h3 class="bright">Linux 32bit</h3>
Black Box competition module for Unix/Linux.
The software has been tested on Ubuntu 14.04.1 LTS.
</td><td width="300">
<a href="downloads/bbcomp-linux-32bit.zip">bbcomp-linux-32bit.zip</a>
</td></tr>
--> 
       <tr>
        <td> <h3 class="bright">Linux 64bit</h3> Black Box competition module for Unix/Linux. The software has been tested on Linux Mint. </td>
        <td width="300"> <a href="downloads/bbcomp-linux-64bit.zip">bbcomp-linux-64bit.zip</a> </td>
       </tr> 
       <tr>
        <td> <h3 class="bright">MacOS</h3> Black Box competition module for Mac OS X. The software has been tested on Mac OS X Mavericks (10.9.5). </td>
        <td width="300"> <a href="downloads/bbcomp-mac.zip">bbcomp-mac.zip</a> </td>
       </tr> 
       <tr>
        <td> <h3 class="bright">Real-world&nbsp;Problems</h3> Source code of the real-world problems used in the corresponding EMO'2017 track. </td>
        <td width="300"> <a href="downloads/realworld-problems-bbcomp-EMO-2017.zip">realworld-problems-bbcomp-EMO-2017.zip</a> </td>
       </tr> 
      </tbody>
     </table> 
    </div> 
    <!--
<p>
We stopped shipping 32bit versions of the software. If you really need a
32bit version then please send a request to
<a href="mailto:blackboxcompetition@gmail.com">blackboxcompetition@gmail.com</a>.
We will re-enable 32bit builds only in case of strong popular demand.
</p>
--> 
    <p> Bindings for the library have been created in several languages and are freely available – thanks for sharing! </p>
    <ul> 
     <li> An R language client by Andrzej Fiedukowicz is available at <a target="_blank" href="https://github.com/fiedukow/RBBComp">https://github.com/fiedukow/RBBComp</a>. </li> 
     <li> A LUCK language client by Andrew Johnson is available at <a target="_blank" href="http://luck.subarctic.org/example/bbcomp">http://luck.subarctic.org/example/bbcomp</a>. </li> 
    </ul> Note: These bindings are not maintained by the competition organizers. They may be outdated or cover only a subset of the functionality. In particular, they may not support multi-objective optimization yet. 
    <p></p> 
    <a name="results"></a> 
    <h2>Results</h2> 
    <p> Summary of the results of the GECCO'2017 competition: </p>
    <ul> 
     <li><a href="results/BBComp2017-1OBJ/summary.html">GECCO&nbsp;2017 single-objective track</a></li> 
     <li><a href="results/BBComp2017-1OBJ-expensive/summary.html">GECCO&nbsp;2017 expensive single-objective track</a></li> 
     <li><a href="results/BBComp2017-2OBJ/summary.html">GECCO&nbsp;2017 two-objective track</a></li> 
     <li><a href="results/BBComp2017-2OBJ-expensive/summary.html">GECCO&nbsp;2017 expensive two-objective track</a></li> 
     <li><a href="results/BBComp2017-3OBJ/summary.html">GECCO&nbsp;2017 three-objective track</a></li> 
    </ul> Summaries of the results of previous iterations of BBComp: 
    <ul> 
     <li><a href="results/BBComp2017EMO/summary.html">EMO&nbsp;2017 real-world problems track</a></li> 
     <li><a href="results/BBComp2016-1OBJ/summary.html">GECCO&nbsp;2016 single-objective track</a></li> 
     <li><a href="results/BBComp2016-1OBJ-expensive/summary.html">GECCO&nbsp;2016 expensive single-objective track</a></li> 
     <li><a href="results/BBComp2016-2OBJ/summary.html">GECCO&nbsp;2016 two-objective track</a></li> 
     <li><a href="results/BBComp2016-2OBJ-expensive/summary.html">GECCO&nbsp;2016 expensive two-objective track</a></li> 
     <li><a href="results/BBComp2016-3OBJ/summary.html">GECCO&nbsp;2016 three-objective track</a></li> 
     <li><a href="results/BBComp2015CEC/summary.html">CEC&nbsp;2015 track</a></li> 
     <li><a href="results/BBComp2015GECCO/summary.html">GECCO&nbsp;2015 track</a></li> 
    </ul> 
    <p></p> 
    <a name="documentation"></a> 
    <h2>Documentation</h2> 
    <p> Detailed documentation is available <a target="_blank" href="documentation.html">on a separate page.</a> </p> 
    <a name="faq"></a> 
    <h2>Frequently Asked Questions</h2> 
    <p> The FAQ is found <a target="_blank" href="faq.html">on a separate page.</a> </p> 
    <a name="related"></a> 
    <h2>Related Material</h2> 
    <p> We would like to provide links to related material on black box optimization benchmarking and corresponding conferences: </p>
    <ul> 
     <li><a target="_blank" href="http://gecco-2017.sigevo.org/">GECCO'2017</a></li> 
     <li><a target="_blank" href="http://numbbo.github.io/workshops/BBOB-2016/index.html">Black-Box Optimization Benchmarking (BBOB) 2016, including multi-objective optimization for the first time</a></li> 
     <li><a target="_blank" href="http://gecco-2016.sigevo.org/">GECCO'2016</a></li> 
     <li><a target="_blank" href="http://coco.gforge.inria.fr/doku.php?id=cec-bbob-2015">Black-Box Optimization Benchmarking at CEC'2015 (CEC-BBOB)</a></li> 
     <li><a target="_blank" href="http://www.ntu.edu.sg/home/EPNSugan/index_files/CEC2015/CEC2015.htm">CEC'2015 Special Session / Competition on Real Parameter Single Objective Optimization</a></li> 
     <li><a target="_blank" href="http://goanna.cs.rmit.edu.au/~xiaodong/lsgo-competition-cec15/index.html">CEC'2015 Competition on Large Scale Global Optimization</a></li> 
     <li><a target="_blank" href="http://sites.ieee.org/cec2015/">CEC'2015</a></li> 
     <li><a target="_blank" href="http://www.sigevo.org/gecco-2015/">GECCO'2015</a></li> 
    </ul> 
    <p></p> 
    <h2>About</h2> 
    <p id="about1"> The black box competition is organized by <a target="_blank" href="http://loshchilov.com/">Ilya Loshchilov</a> and <a target="_blank" href="http://www.ini.rub.de/PEOPLE/glasmtbl/">Tobias Glasmachers</a>. They hold the copyright on all material provided on this website. The material is <a target="_blank" href="license.html">licensed</a> for the purpose of participation in the competition. </p> 
    <h2>Feedback</h2> 
    <p> We are eager to receive feedback from participants. Don't hesitate to ask questions, propose features, report bugs, start discussions, and share your thoughts and opinions. Write to <a href="mailto:blackboxcompetition@gmail.com">blackboxcompetition@gmail.com</a>. </p> 
    <h2>Sponsors</h2> 
    <p id="about1"> We would like to thank <a href="http://www.msr-inria.fr/">Microsoft Research – Inria joint centre</a> for sponsoring the GECCO'2015 track, more specifically, <a href="http://research.microsoft.com/en-us/people/youssefh/">Youssef Hamadi</a> and <a href="http://www.msr-inria.fr/researchers/laurent-massoulie/">Laurent Massoulie</a> for their interest and support. </p> 
    <h2>Acknowledgements</h2> 
    <p id="about1"> We would like to thank Giovanni Iacca for valuable discussions. </p> 
   </div> 
  </div> 
  <script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-56265968-1', 'auto');
  ga('send', 'pageview');

</script>   
 </body>
</html>