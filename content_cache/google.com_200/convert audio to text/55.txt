<!--?xml version="1.0" encoding="UTF-8"?--><!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
 <head> 
  <meta content="text/html; charset=utf-8" http-equiv="content-type"> 
  <title>SpeechRecognition 3.7.1 : Python Package Index</title> 
  <meta content="speech recognition voice sphinx google wit bing api houndify ibm"> 
  <meta content="Library for performing speech recognition, with support for several engines and APIs, online and offline."> 
  <link rel="alternate" type="application/rss+xml" title="RSS: 40 latest updates" href="https://pypi.python.org/pypi?:action=rss"> 
  <link rel="alternate" type="application/rss+xml" title="RSS: 40 newest packages" href="https://pypi.python.org/pypi?:action=packages_rss"> 
  <link rel="stylesheet" media="screen" href="/static/styles/screen-switcher-default.css" type="text/css"> 
  <link media="screen" href="/static/styles/netscape4.css" type="text/css" rel="stylesheet"> 
  <link media="print" href="/static/styles/print.css" type="text/css" rel="stylesheet"> 
  <link media="screen" href="/static/styles/largestyles.css" type="text/css" rel="alternate stylesheet" title="large text"> 
  <link media="screen" href="/static/styles/defaultfonts.css" type="text/css" rel="alternate stylesheet" title="default fonts"> 
  <link rel="stylesheet" media="screen" href="/static/css/docutils.css" type="text/css"> 
  <link rel="stylesheet" media="screen" href="/static/css/pygments.css" type="text/css"> 
  <!-- allow pypi to override the standard pydotorg/docutils/etc. styles --> 
  <link rel="stylesheet" href="/static/css/pypi.css" type="text/css"> 
  <link media="screen" rel="stylesheet" href="/static/css/pypi-screen.css" type="text/css"> 
  <meta name="google-site-verification" content="NSgF04qslVV4P7nymxJDSkWVK09zfdPTxgZfU3dNSoQ"> 
  <meta name="keywords" content="speech recognition voice sphinx google wit bing api houndify ibm"> 
  <meta name="description" content="Library for performing speech recognition, with support for several engines and APIs, online and offline."> 
  <link rel="meta" title="DOAP" type="application/rdf+xml" href="/pypi?:action=doap&amp;name=SpeechRecognition&amp;version=3.7.1"> 
  <style type="text/css">
  table.form th {white-space: pre;}
 </style> 
  <style type="text/css">
       </style> 
 </head> 
 <body> 
  <!--  Logo  --> 
  <h1 id="logoheader"> <a accesskey="1" href="http://www.python.org" id="logolink"> <img src="/static/images/python-logo.png" alt="homepage" border="0" id="logo"> </a> </h1> 
  <!--  Skip to Navigation  --> 
  <div class="skiptonav">
   <a accesskey="2" href="#left-hand-navigation"><img src="/static/images/trans.gif" alt="skip to navigation" border="0" id="skiptonav"></a>
  </div> 
  <div class="skiptonav">
   <a accesskey="3" href="#content-body"><img src="/static/images/trans.gif" alt="skip to content" border="0" id="skiptocontent"></a>
  </div> 
  <!--  Utility Menu  --> 
  <div id="utility-menu"> 
   <!--  Search Box  --> 
   <div id="searchbox"> 
    <form id="searchform" method="get" name="searchform" action="/pypi"> 
     <input type="hidden" name=":action" value="search"> 
     <div id="search"> 
      <input class="input-text" id="term" name="term" autofocus> 
      <input class="input-button" type="submit" name="submit" value="search" id="submit"> 
     </div> 
    </form> 
   </div> 
   <!-- XXX: reinstate this       <div id="screen-switcher"></div> --> 
  </div> 
  <div id="left-hand-navigation"> 
   <!--  Main Menu NEED LEVEL TWO HEADER AND FOOTER --> 
   <div id="menu"> 
    <ul class="level-one"> 
     <li class="selected"> <a class="selected" href="/pypi">Package Index</a> 
      <ul class="level-two"> 
       <li class=""><a class="" href="/pypi?%3Aaction=browse">Browse&nbsp;packages</a></li> 
       <li class=""><a class="" href="/pypi?%3Aaction=list_classifiers">List&nbsp;trove&nbsp;classifiers</a></li> 
       <li class=""><a class="" href="/pypi?%3Aaction=rss">RSS&nbsp;(latest&nbsp;40&nbsp;updates)</a></li> 
       <li class=""><a class="" href="/pypi?%3Aaction=packages_rss">RSS&nbsp;(newest&nbsp;40&nbsp;packages)</a></li> 
       <li><a href="/tos">Terms of Service</a></li> 
       <li><a href="http://wiki.python.org/moin/CheeseShopTutorial">PyPI Tutorial</a></li> 
       <li><a href="/security">PyPI Security</a></li> 
       <li><a href="http://sourceforge.net/tracker/?group_id=66150&amp;atid=513504">PyPI Support</a></li> 
       <li><a href="https://github.com/pypa/pypi-legacy/issues">PyPI Bug Reports</a></li> 
       <li><a href="http://www.python.org/sigs/distutils-sig/">PyPI Discussion</a></li> 
       <li><a href="http://wiki.python.org/moin/CheeseShopDev">PyPI Developer Info</a></li> 
      </ul> </li> 
     <li class=""><a href="http://www.python.org/about" class="" title="About The Python Language">About</a> </li>
     <li class=""><a href="http://www.python.org/news" class="" title="">News</a> </li>
     <li class=""><a href="http://www.python.org/doc" class="" title="">Documentation</a> </li>
     <li class=""><a href="http://www.python.org/download" title="">Download</a> </li>
     <li class=""><a href="http://www.python.org/community" class="" title="">Community</a> </li>
     <li class=""><a href="http://www.python.org/psf" class="" title="Python Software Foundation">Foundation</a> </li>
     <li class=""><a href="http://www.python.org/dev" class="" title="Python Core Language Development">Core Development</a> </li> 
    </ul> 
   </div> 
  </div> 
  <div id="content-body"> 
   <div id="body-main"> 
    <div id="content"> 
     <div id="breadcrumb"> 
      <a href="/pypi">Package Index</a> 
      <span class="breadcrumb-separator">&gt;</span> 
      <a href="/pypi/SpeechRecognition">SpeechRecognition</a> 
      <span class="breadcrumb-separator">&gt;</span> 
      <a href="/pypi/SpeechRecognition/3.7.1">3.7.1</a> 
     </div> 
     <div id="document-floating"> 
      <div id="document-navigation" style="overflow-y: auto; max-height: 15em; overflow-x: hidden;"> 
       <h4>Not Logged In</h4> 
       <ul> 
        <li><a href="/pypi?%3Aaction=login_form">Login</a></li> 
        <li><a href="/pypi?%3Aaction=register_form">Register</a></li> 
        <li><a href="/pypi?%3Aaction=forgotten_password_form">Lost Login?</a></li> 
        <li><a href="/openid_login">Login with OpenID</a> <a style="border: none;" href="/openid_login?provider=Launchpad"><img width="16" height="16" alt="Launchpad" src="https://launchpad.net/@@/launchpad.png" title="Launchpad"></a> </li> 
        <li><a href="/google_login">Login with Google<img width="16" height="16" src="https://www.google.com/favicon.ico" title="Google Login" alt="Google Login"></a></li> 
       </ul> 
       <div id="statusdiv"> 
       </div> 
      </div> 
     </div> 
     <div class="section"> 
      <h1>SpeechRecognition 3.7.1</h1> 
      <div id="download-button"> 
       <a class="button green" style="float:right;" href="https://pypi.python.org/packages/aa/99/18926cba2e18453756a90332d871541a26f8f9e81dbfc4bed0e7d3ffbf04/SpeechRecognition-3.7.1-py2.py3-none-any.whl">Download<br> <span style="font-size: 75%">SpeechRecognition-3.7.1-py2.py3-none-any.whl</span> </a> 
      </div> 
      <p style="font-style: italic">Library for performing speech recognition, with support for several engines and APIs, online and offline.</p> 
      <a href="https://pypi.python.org/pypi/SpeechRecognition/" rel="nofollow"><img src="https://img.shields.io/pypi/v/SpeechRecognition.svg"> </a> 
      <a href="https://pypi.python.org/pypi/SpeechRecognition/" rel="nofollow"><img src="https://img.shields.io/pypi/status/SpeechRecognition.svg"> </a> 
      <a href="https://pypi.python.org/pypi/SpeechRecognition/" rel="nofollow"><img src="https://img.shields.io/pypi/pyversions/SpeechRecognition.svg"> </a> 
      <a href="https://pypi.python.org/pypi/SpeechRecognition/" rel="nofollow"><img src="https://img.shields.io/pypi/l/SpeechRecognition.svg"> </a> 
      <a href="https://travis-ci.org/Uberi/speech_recognition" rel="nofollow"><img src="https://api.travis-ci.org/Uberi/speech_recognition.svg?branch=master"></a> 
      <p>Library for performing speech recognition, with support for several engines and APIs, online and offline.</p> 
      <p>Speech recognition engine/API support:</p> 
      <ul> 
       <li><a href="http://cmusphinx.sourceforge.net/wiki/" rel="nofollow">CMU Sphinx</a> (works offline)</li> 
       <li>Google Speech Recognition</li> 
       <li><a href="https://cloud.google.com/speech/" rel="nofollow">Google Cloud Speech API</a></li> 
       <li><a href="https://wit.ai/" rel="nofollow">Wit.ai</a></li> 
       <li><a href="https://www.microsoft.com/cognitive-services/en-us/speech-api" rel="nofollow">Microsoft Bing Voice Recognition</a></li> 
       <li><a href="https://houndify.com/" rel="nofollow">Houndify API</a></li> 
       <li><a href="http://www.ibm.com/smarterplanet/us/en/ibmwatson/developercloud/speech-to-text.html" rel="nofollow">IBM Speech to Text</a></li> 
      </ul> 
      <p><strong>Quickstart:</strong> <tt>pip install SpeechRecognition</tt>. See the “Installing” section for more details.</p> 
      <p>To quickly try it out, run <tt>python <span class="pre">-m</span> speech_recognition</tt> after installing.</p> 
      <p>Project links:</p> 
      <ul> 
       <li><a href="https://pypi.python.org/pypi/SpeechRecognition/" rel="nofollow">PyPI</a></li> 
       <li><a href="https://github.com/Uberi/speech_recognition" rel="nofollow">Source code</a></li> 
       <li><a href="https://github.com/Uberi/speech_recognition/issues" rel="nofollow">Issue tracker</a></li> 
      </ul> 
      <div id="library-reference"> 
       <h2>Library Reference</h2> 
       <p>The <a href="https://github.com/Uberi/speech_recognition/blob/master/reference/library-reference.rst" rel="nofollow">library reference</a> documents every publicly accessible object in the library. This document is also included under <tt><span class="pre">reference/library-reference.rst</span></tt>.</p> 
       <p>See <a href="https://github.com/Uberi/speech_recognition/blob/master/reference/pocketsphinx.rst" rel="nofollow">Notes on using PocketSphinx</a> for information about installing languages, compiling PocketSphinx, and building language packs from online resources. This document is also included under <tt>reference/pocketsphinx.rst</tt>.</p> 
      </div> 
      <div id="examples"> 
       <h2>Examples</h2> 
       <p>See the <tt>examples/</tt> <a href="https://github.com/Uberi/speech_recognition/tree/master/examples" rel="nofollow">directory</a> in the repository root for usage examples:</p> 
       <ul> 
        <li><a href="https://github.com/Uberi/speech_recognition/blob/master/examples/microphone_recognition.py" rel="nofollow">Recognize speech input from the microphone</a></li> 
        <li><a href="https://github.com/Uberi/speech_recognition/blob/master/examples/audio_transcribe.py" rel="nofollow">Transcribe an audio file</a></li> 
        <li><a href="https://github.com/Uberi/speech_recognition/blob/master/examples/write_audio.py" rel="nofollow">Save audio data to an audio file</a></li> 
        <li><a href="https://github.com/Uberi/speech_recognition/blob/master/examples/extended_results.py" rel="nofollow">Show extended recognition results</a></li> 
        <li><a href="https://github.com/Uberi/speech_recognition/blob/master/examples/calibrate_energy_threshold.py" rel="nofollow">Calibrate the recognizer energy threshold for ambient noise levels</a> (see <tt>recognizer_instance.energy_threshold</tt> for details)</li> 
        <li><a href="https://github.com/Uberi/speech_recognition/blob/master/examples/background_listening.py" rel="nofollow">Listening to a microphone in the background</a></li> 
        <li><a href="https://github.com/Uberi/speech_recognition/blob/master/examples/special_recognizer_features.py" rel="nofollow">Various other useful recognizer features</a></li> 
       </ul> 
      </div> 
      <div id="installing"> 
       <h2>Installing</h2> 
       <p>First, make sure you have all the requirements listed in the “Requirements” section.</p> 
       <p>The easiest way to install this is using <tt>pip install SpeechRecognition</tt>.</p> 
       <p>Otherwise, download the source distribution from <a href="https://pypi.python.org/pypi/SpeechRecognition/" rel="nofollow">PyPI</a>, and extract the archive.</p> 
       <p>In the folder, run <tt>python setup.py install</tt>.</p> 
      </div> 
      <div id="requirements"> 
       <h2>Requirements</h2> 
       <p>To use all of the functionality of the library, you should have:</p> 
       <ul> 
        <li><strong>Python</strong> 2.6, 2.7, or 3.3+ (required)</li> 
        <li><strong>PyAudio</strong> 0.2.11+ (required only if you need to use microphone input, <tt>Microphone</tt>)</li> 
        <li><strong>PocketSphinx</strong> (required only if you need to use the Sphinx recognizer, <tt>recognizer_instance.recognize_sphinx</tt>)</li> 
        <li><strong>Google API Client Library for Python</strong> (required only if you need to use the Google Cloud Speech API, <tt>recognizer_instance.recognize_google_cloud</tt>)</li> 
        <li><strong>FLAC encoder</strong> (required only if the system is not x86-based Windows/Linux/OS X)</li> 
       </ul> 
       <p>The following requirements are optional, but can improve or extend functionality in some situations:</p> 
       <ul> 
        <li>On Python 2, and only on Python 2, some functions (like <tt>recognizer_instance.recognize_bing</tt>) will run slower if you do not have <strong>Monotonic for Python 2</strong> installed.</li> 
        <li>If using CMU Sphinx, you may want to <a href="https://github.com/Uberi/speech_recognition/blob/master/reference/pocketsphinx.rst#installing-other-languages" rel="nofollow">install additional language packs</a> to support languages like International French or Mandarin Chinese.</li> 
       </ul> 
       <p>The following sections go over the details of each requirement.</p> 
       <div id="python"> 
        <h3>Python</h3> 
        <p>The first software requirement is <a href="https://www.python.org/download/releases/" rel="nofollow">Python 2.6, 2.7, or Python 3.3+</a>. This is required to use the library.</p> 
       </div> 
       <div id="pyaudio-for-microphone-users"> 
        <h3>PyAudio (for microphone users)</h3> 
        <p><a href="http://people.csail.mit.edu/hubert/pyaudio/#downloads" rel="nofollow">PyAudio</a> is required if and only if you want to use microphone input (<tt>Microphone</tt>). PyAudio version 0.2.11+ is required, as earlier versions have known memory management bugs when recording from microphones in certain situations.</p> 
        <p>If not installed, everything in the library will still work, except attempting to instantiate a <tt>Microphone</tt> object will raise an <tt>AttributeError</tt>.</p> 
        <p>The installation instructions on the PyAudio website are quite good - for convenience, they are summarized below:</p> 
        <ul> 
         <li><p>On Windows, install PyAudio using <a href="https://pip.readthedocs.org/" rel="nofollow">Pip</a>: execute <tt>pip install pyaudio</tt> in a terminal.</p> </li> 
         <li>
          <dl> 
           <dt>
            On Debian-derived Linux distributions (like Ubuntu and Mint), install PyAudio using 
            <a href="https://wiki.debian.org/Apt" rel="nofollow">APT</a>: execute 
            <tt>sudo <span class="pre">apt-get</span> install <span class="pre">python-pyaudio</span> <span class="pre">python3-pyaudio</span></tt> in a terminal.
           </dt> 
           <dd>
            <ul> 
             <li>If the version in the repositories is too old, install the latest release using Pip: execute <tt>sudo <span class="pre">apt-get</span> install <span class="pre">portaudio19-dev</span> <span class="pre">python-all-dev</span> <span class="pre">python3-all-dev</span> &amp;&amp; sudo pip install pyaudio</tt> (replace <tt>pip</tt> with <tt>pip3</tt> if using Python 3).</li> 
            </ul> 
           </dd> 
          </dl> </li> 
         <li><p>On OS X, install PortAudio using <a href="http://brew.sh/" rel="nofollow">Homebrew</a>: <tt>brew install portaudio</tt>. Then, install PyAudio using <a href="https://pip.readthedocs.org/" rel="nofollow">Pip</a>: <tt>pip install pyaudio</tt>.</p> </li> 
         <li><p>On other POSIX-based systems, install the <tt><span class="pre">portaudio19-dev</span></tt> and <tt><span class="pre">python-all-dev</span></tt> (or <tt><span class="pre">python3-all-dev</span></tt> if using Python 3) packages (or their closest equivalents) using a package manager of your choice, and then install PyAudio using <a href="https://pip.readthedocs.org/" rel="nofollow">Pip</a>: <tt>pip install pyaudio</tt> (replace <tt>pip</tt> with <tt>pip3</tt> if using Python 3).</p> </li> 
        </ul> 
        <p>PyAudio <a href="https://pypi.python.org/pypi/wheel" rel="nofollow">wheel packages</a> for common 64-bit Python versions on Windows and Linux are included for convenience, under the <tt><span class="pre">third-party/</span></tt> <a href="https://github.com/Uberi/speech_recognition/tree/master/third-party" rel="nofollow">directory</a> in the repository root. To install, simply run <tt>pip install wheel</tt> followed by <tt>pip install <span class="pre">./third-party/WHEEL_FILENAME</span></tt> (replace <tt>pip</tt> with <tt>pip3</tt> if using Python 3) in the repository <a href="https://github.com/Uberi/speech_recognition" rel="nofollow">root directory</a>.</p> 
       </div> 
       <div id="pocketsphinx-python-for-sphinx-users"> 
        <h3>PocketSphinx-Python (for Sphinx users)</h3> 
        <p><a href="https://github.com/bambocher/pocketsphinx-python" rel="nofollow">PocketSphinx-Python</a> is <strong>required if and only if you want to use the Sphinx recognizer</strong> (<tt>recognizer_instance.recognize_sphinx</tt>).</p> 
        <p>PocketSphinx-Python <a href="https://pypi.python.org/pypi/wheel" rel="nofollow">wheel packages</a> for 64-bit Python 2.7, 3.4, and 3.5 on Windows are included for convenience, under the <tt><span class="pre">third-party/</span></tt> <a href="https://github.com/Uberi/speech_recognition/tree/master/third-party" rel="nofollow">directory</a>. To install, simply run <tt>pip install wheel</tt> followed by <tt>pip install <span class="pre">./third-party/WHEEL_FILENAME</span></tt> (replace <tt>pip</tt> with <tt>pip3</tt> if using Python 3) in the SpeechRecognition folder.</p> 
        <p>On Linux and other POSIX systems (such as OS X), follow the instructions under “Building PocketSphinx-Python from source” in <a href="https://github.com/Uberi/speech_recognition/blob/master/reference/pocketsphinx.rst" rel="nofollow">Notes on using PocketSphinx</a> for installation instructions.</p> 
        <p>Note that the versions available in most package repositories are outdated and will not work with the bundled language data. Using the bundled wheel packages or building from source is recommended.</p> 
        <p>See <a href="https://github.com/Uberi/speech_recognition/blob/master/reference/pocketsphinx.rst" rel="nofollow">Notes on using PocketSphinx</a> for information about installing languages, compiling PocketSphinx, and building language packs from online resources. This document is also included under <tt>reference/pocketsphinx.rst</tt>.</p> 
       </div> 
       <div id="google-api-client-library-for-python-for-google-cloud-speech-api-users"> 
        <h3>Google API Client Library for Python (for Google Cloud Speech API users)</h3> 
        <p><a href="https://developers.google.com/api-client-library/python/" rel="nofollow">Google API Client Library for Python</a> is required if and only if you want to use the Google Cloud Speech API (<tt>recognizer_instance.recognize_google_cloud</tt>).</p> 
        <p>If not installed, everything in the library will still work, except calling <tt>recognizer_instance.recognize_google_cloud</tt> will raise an <tt>RequestError</tt>.</p> 
        <p>According to the <a href="https://developers.google.com/api-client-library/python/start/installation" rel="nofollow">official installation instructions</a>, the recommended way to install this is using <a href="https://pip.readthedocs.org/" rel="nofollow">Pip</a>: execute <tt>pip install <span class="pre">google-api-python-client</span></tt> (replace <tt>pip</tt> with <tt>pip3</tt> if using Python 3).</p> 
        <p>Alternatively, you can perform the installation completely offline from the source archives under the <tt><span class="pre">./third-party/Source</span> code for Google API Client Library for Python and its dependencies/</tt> directory.</p> 
       </div> 
       <div id="flac-for-some-systems"> 
        <h3>FLAC (for some systems)</h3> 
        <p>A <a href="https://xiph.org/flac/" rel="nofollow">FLAC encoder</a> is required to encode the audio data to send to the API. If using Windows (x86 or x86-64), OS X (Intel Macs only, OS X 10.6 or higher), or Linux (x86 or x86-64), this is <strong>already bundled with this library - you do not need to install anything</strong>.</p> 
        <p>Otherwise, ensure that you have the <tt>flac</tt> command line tool, which is often available through the system package manager. For example, this would usually be <tt>sudo <span class="pre">apt-get</span> install flac</tt> on Debian-derivatives, or <tt>brew install flac</tt> on OS X with Homebrew.</p> 
       </div> 
       <div id="monotonic-for-python-2-for-faster-operations-in-some-functions-on-python-2"> 
        <h3>Monotonic for Python 2 (for faster operations in some functions on Python 2)</h3> 
        <p>On Python 2, and only on Python 2, if you do not install the <a href="https://github.com/atdt/monotonic" rel="nofollow">Monotonic for Python 2</a> library, some functions will run slower than they otherwise could (though everything will still work correctly).</p> 
        <p>On Python 3, that library’s functionality is built into the Python standard library, which makes it unnecessary.</p> 
        <p>This is because monotonic time is necessary to handle cache expiry properly in the face of system time changes and other time-related issues. If monotonic time functionality is not available, then things like access token requests will not be cached.</p> 
        <p>To install, use <a href="https://pip.readthedocs.org/" rel="nofollow">Pip</a>: execute <tt>pip install monotonic</tt> in a terminal.</p> 
       </div> 
      </div> 
      <div id="troubleshooting"> 
       <h2>Troubleshooting</h2> 
       <div id="the-recognizer-tries-to-recognize-speech-even-when-i-m-not-speaking-or-after-i-m-done-speaking"> 
        <h3>The recognizer tries to recognize speech even when I’m not speaking, or after I’m done speaking.</h3> 
        <p>Try increasing the <tt>recognizer_instance.energy_threshold</tt> property. This is basically how sensitive the recognizer is to when recognition should start. Higher values mean that it will be less sensitive, which is useful if you are in a loud room.</p> 
        <p>This value depends entirely on your microphone or audio data. There is no one-size-fits-all value, but good values typically range from 50 to 4000.</p> 
        <p>Also, check on your microphone volume settings. If it is too sensitive, the microphone may be picking up a lot of ambient noise. If it is too insensitive, the microphone may be rejecting speech as just noise.</p> 
       </div> 
       <div id="the-recognizer-can-t-recognize-speech-right-after-it-starts-listening-for-the-first-time"> 
        <h3>The recognizer can’t recognize speech right after it starts listening for the first time.</h3> 
        <p>The <tt>recognizer_instance.energy_threshold</tt> property is probably set to a value that is too high to start off with, and then being adjusted lower automatically by dynamic energy threshold adjustment. Before it is at a good level, the energy threshold is so high that speech is just considered ambient noise.</p> 
        <p>The solution is to decrease this threshold, or call <tt>recognizer_instance.adjust_for_ambient_noise</tt> beforehand, which will set the threshold to a good value automatically.</p> 
       </div> 
       <div id="the-recognizer-doesn-t-understand-my-particular-language-dialect"> 
        <h3>The recognizer doesn’t understand my particular language/dialect.</h3> 
        <p>Try setting the recognition language to your language/dialect. To do this, see the documentation for <tt>recognizer_instance.recognize_sphinx</tt>, <tt>recognizer_instance.recognize_google</tt>, <tt>recognizer_instance.recognize_wit</tt>, <tt>recognizer_instance.recognize_bing</tt>, <tt>recognizer_instance.recognize_api</tt>, <tt>recognizer_instance.recognize_houndify</tt>, and <tt>recognizer_instance.recognize_ibm</tt>.</p> 
        <p>For example, if your language/dialect is British English, it is better to use <tt><span class="pre">"en-GB"</span></tt> as the language rather than <tt><span class="pre">"en-US"</span></tt>.</p> 
       </div> 
       <div id="the-recognizer-hangs-on-recognizer-instance-listen-specifically-when-it-s-calling-microphone-microphonestream-read"> 
        <h3>The recognizer hangs on <tt>recognizer_instance.listen</tt>; specifically, when it’s calling <tt>Microphone.MicrophoneStream.read</tt>.</h3> 
        <p>This usually happens when you’re using a Raspberry Pi board, which doesn’t have audio input capabilities by itself. This causes the default microphone used by PyAudio to simply block when we try to read it. If you happen to be using a Raspberry Pi, you’ll need a USB sound card (or USB microphone).</p> 
        <p>Once you do this, change all instances of <tt>Microphone()</tt> to <tt>Microphone(device_index=MICROPHONE_INDEX)</tt>, where <tt>MICROPHONE_INDEX</tt> is the hardware-specific index of the microphone.</p> 
        <p>To figure out what the value of <tt>MICROPHONE_INDEX</tt> should be, run the following code:</p> 
        <pre><span class="kn">import</span> <span class="nn">speech_recognition</span> <span class="kn">as</span> <span class="nn">sr</span>
<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sr</span><span class="o">.</span><span class="n">Microphone</span><span class="o">.</span><span class="n">list_microphone_names</span><span class="p">()):</span>
    <span class="k">print</span><span class="p">(</span><span class="s2">"Microphone with name </span><span class="se">\"</span><span class="s2">{1}</span><span class="se">\"</span><span class="s2"> found for `Microphone(device_index={0})`"</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">index</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span>
</pre> 
        <p>This will print out something like the following:</p> 
        <pre>Microphone with name "HDA Intel HDMI: 0 (hw:0,3)" found for `Microphone(device_index=0)`
Microphone with name "HDA Intel HDMI: 1 (hw:0,7)" found for `Microphone(device_index=1)`
Microphone with name "HDA Intel HDMI: 2 (hw:0,8)" found for `Microphone(device_index=2)`
Microphone with name "Blue Snowball: USB Audio (hw:1,0)" found for `Microphone(device_index=3)`
Microphone with name "hdmi" found for `Microphone(device_index=4)`
Microphone with name "pulse" found for `Microphone(device_index=5)`
Microphone with name "default" found for `Microphone(device_index=6)`
</pre> 
        <p>Now, to use the Snowball microphone, you would change <tt>Microphone()</tt> to <tt>Microphone(device_index=3)</tt>.</p> 
       </div> 
       <div id="the-code-examples-raise-unicodeencodeerror-ascii-codec-can-t-encode-character-when-run"> 
        <h3>The code examples raise <tt>UnicodeEncodeError: 'ascii' codec can't encode character</tt> when run.</h3> 
        <p>When you’re using Python 2, and your language uses non-ASCII characters, and the terminal or file-like object you’re printing to only supports ASCII, an error is raised when trying to write non-ASCII characters.</p> 
        <p>This is because in Python 2, <tt>recognizer_instance.recognize_sphinx</tt>, <tt>recognizer_instance.recognize_google</tt>, <tt>recognizer_instance.recognize_wit</tt>, <tt>recognizer_instance.recognize_bing</tt>, <tt>recognizer_instance.recognize_api</tt>, <tt>recognizer_instance.recognize_houndify</tt>, and <tt>recognizer_instance.recognize_ibm</tt> return unicode strings (<tt>u"something"</tt>) rather than byte strings (<tt>"something"</tt>). In Python 3, all strings are unicode strings.</p> 
        <p>To make printing of unicode strings work in Python 2 as well, replace all print statements in your code of the following form:</p> 
        <blockquote> 
         <pre><span class="k">print</span> <span class="n">SOME_UNICODE_STRING</span>
</pre> 
        </blockquote> 
        <p>With the following:</p> 
        <blockquote> 
         <pre><span class="k">print</span> <span class="n">SOME_UNICODE_STRING</span><span class="o">.</span><span class="n">encode</span><span class="p">(</span><span class="s2">"utf8"</span><span class="p">)</span>
</pre> 
        </blockquote> 
        <p>This change, however, will prevent the code from working in Python 3.</p> 
       </div> 
       <div id="the-program-doesn-t-run-when-compiled-with-pyinstaller"> 
        <h3>The program doesn’t run when compiled with <a href="https://github.com/pyinstaller/pyinstaller/wiki" rel="nofollow">PyInstaller</a>.</h3> 
        <p>As of PyInstaller version 3.0, SpeechRecognition is supported out of the box. If you’re getting weird issues when compiling your program using PyInstaller, simply update PyInstaller.</p> 
        <p>You can easily do this by running <tt>pip install <span class="pre">--upgrade</span> pyinstaller</tt>.</p> 
       </div> 
       <div id="on-ubuntu-debian-i-get-annoying-output-in-the-terminal-saying-things-like-bt-audio-service-open-connection-refused-and-various-others"> 
        <h3>On Ubuntu/Debian, I get annoying output in the terminal saying things like “bt_audio_service_open: […] Connection refused” and various others.</h3> 
        <p>The “bt_audio_service_open” error means that you have a Bluetooth audio device, but as a physical device is not currently connected, we can’t actually use it - if you’re not using a Bluetooth microphone, then this can be safely ignored. If you are, and audio isn’t working, then double check to make sure your microphone is actually connected. There does not seem to be a simple way to disable these messages.</p> 
        <p>For errors of the form “ALSA lib […] Unknown PCM”, see <a href="http://stackoverflow.com/questions/7088672/pyaudio-working-but-spits-out-error-messages-each-time" rel="nofollow">this StackOverflow answer</a>. Basically, to get rid of an error of the form “Unknown PCM cards.pcm.rear”, simply comment out <tt>pcm.rear cards.pcm.rear</tt> in <tt>/usr/share/alsa/alsa.conf</tt>, <tt><span class="pre">~/.asoundrc</span></tt>, and <tt>/etc/asound.conf</tt>.</p> 
        <p>For “jack server is not running or cannot be started” or “connect(2) call to /dev/shm/jack-1000/default/jack_0 failed (err=No such file or directory)” or “attempt to connect to server failed”, these are caused by ALSA trying to connect to JACK, and can be safely ignored. I’m not aware of any simple way to turn those messages off at this time, besides [entirely disabling printing while starting the microphone](<a href="https://github.com/Uberi/speech_recognition/issues/182#issuecomment-266256337" rel="nofollow">https://github.com/Uberi/speech_recognition/issues/182#issuecomment-266256337</a>).</p> 
       </div> 
       <div id="on-os-x-i-get-a-childprocesserror-saying-that-it-couldn-t-find-the-system-flac-converter-even-though-it-s-installed"> 
        <h3>On OS X, I get a <tt>ChildProcessError</tt> saying that it couldn’t find the system FLAC converter, even though it’s installed.</h3> 
        <p>Installing <a href="https://xiph.org/flac/download.html" rel="nofollow">FLAC for OS X</a> directly from the source code will not work, since it doesn’t correctly add the executables to the search path.</p> 
        <p>Installing FLAC using <a href="http://brew.sh/" rel="nofollow">Homebrew</a> ensures that the search path is correctly updated. First, ensure you have Homebrew, then run <tt>brew install flac</tt> to install the necessary files.</p> 
       </div> 
      </div> 
      <div id="developing"> 
       <h2>Developing</h2> 
       <p>To hack on this library, first make sure you have all the requirements listed in the “Requirements” section.</p> 
       <ul> 
        <li>Most of the library code lives in <tt>speech_recognition/__init__.py</tt>.</li> 
        <li>Examples live under the <tt>examples/</tt> <a href="https://github.com/Uberi/speech_recognition/tree/master/examples" rel="nofollow">directory</a>, and the demo script lives in <tt>speech_recognition/__main__.py</tt>.</li> 
        <li>The FLAC encoder binaries are in the <tt>speech_recognition/</tt> <a href="https://github.com/Uberi/speech_recognition/tree/master/speech_recognition" rel="nofollow">directory</a>.</li> 
        <li>Documentation can be found in the <tt>reference/</tt> <a href="https://github.com/Uberi/speech_recognition/tree/master/reference" rel="nofollow">directory</a>.</li> 
        <li>Third-party libraries, utilities, and reference material are in the <tt><span class="pre">third-party/</span></tt> <a href="https://github.com/Uberi/speech_recognition/tree/master/third-party" rel="nofollow">directory</a>.</li> 
       </ul> 
       <p>To install/reinstall the library locally, run <tt>python setup.py install</tt> in the project <a href="https://github.com/Uberi/speech_recognition" rel="nofollow">root directory</a>.</p> 
       <p>Before a release, the version number is bumped in <tt>README.rst</tt> and <tt>speech_recognition/__init__.py</tt>. Version tags are then created using <tt>git config gpg.program gpg2 &amp;&amp; git config user.signingkey DB45F6C431DE7C2DCD99FF7904882258A4063489 &amp;&amp; git tag <span class="pre">-s</span> VERSION_GOES_HERE <span class="pre">-m</span> "Version VERSION_GOES_HERE"</tt>.</p> 
       <p>Releases are done by running <tt><span class="pre">make-release.sh</span></tt> to build the Python source packages, sign them, and upload them to PyPI.</p> 
       <div id="testing"> 
        <h3>Testing</h3> 
        <p>To run all the tests:</p> 
        <pre>python -m unittest discover --verbose
</pre> 
        <p>Testing is also done automatically by TravisCI, upon every push. To set up the environment for offline/local Travis-like testing on a Debian-like system:</p> 
        <pre>sudo docker run --volume <span class="s2">"</span><span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span><span class="s2">:/speech_recognition"</span> --interactive --tty quay.io/travisci/travis-python:latest /bin/bash
su - travis <span class="o">&amp;&amp;</span> <span class="nb">cd</span> /speech_recognition
sudo apt-get update <span class="o">&amp;&amp;</span> sudo apt-get install swig libpulse-dev
pip install --user pocketsphinx monotonic <span class="o">&amp;&amp;</span> pip install --user flake8 rstcheck <span class="o">&amp;&amp;</span> pip install --user -e .
python -m unittest discover --verbose <span class="c1"># run unit tests
</span>python -m flake8 --ignore<span class="o">=</span>E501,E701 speech_recognition tests examples setup.py <span class="c1"># ignore errors for long lines and multi-statement lines
</span>python -m rstcheck README.rst reference/*.rst <span class="c1"># ensure RST is well-formed</span>
</pre> 
       </div> 
       <div id="flac-executables"> 
        <h3>FLAC Executables</h3> 
        <p>The included <tt><span class="pre">flac-win32</span></tt> executable is the <a href="http://downloads.xiph.org/releases/flac/flac-1.3.2-win.zip" rel="nofollow">official FLAC 1.3.2 32-bit Windows binary</a>.</p> 
        <p>The included <tt><span class="pre">flac-linux-x86</span></tt> and <tt><span class="pre">flac-linux-x86_64</span></tt> executables are built from the <a href="http://downloads.xiph.org/releases/flac/flac-1.3.2.tar.xz" rel="nofollow">FLAC 1.3.2 source code</a> with <a href="https://github.com/pypa/manylinux" rel="nofollow">Manylinux</a> to ensure that it’s compatible with a wide variety of distributions.</p> 
        <p>The built FLAC executables should be bit-for-bit reproducible. To rebuild them, run the following inside the project directory on a Debian-like system:</p> 
        <pre><span class="c1"># download and extract the FLAC source code
</span><span class="nb">cd</span> third-party
sudo apt-get install --yes docker.io

<span class="c1"># build FLAC inside the Manylinux i686 Docker image
</span>tar xf flac-1.3.2.tar.xz
sudo docker run --tty --interactive --rm --volume <span class="s2">"</span><span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span><span class="s2">:/root"</span> quay.io/pypa/manylinux1_i686:latest bash
    <span class="nb">cd</span> /root/flac-1.3.2
    ./configure <span class="nv">LDFLAGS</span><span class="o">=</span>-static <span class="c1"># compiler flags to make a static build
</span>    make
<span class="nb">exit</span>
cp flac-1.3.2/src/flac/flac ../speech_recognition/flac-linux-x86 <span class="o">&amp;&amp;</span> sudo rm -rf flac-1.3.2/

<span class="c1"># build FLAC inside the Manylinux x86_64 Docker image
</span>tar xf flac-1.3.2.tar.xz
sudo docker run --tty --interactive --rm --volume <span class="s2">"</span><span class="k">$(</span><span class="nb">pwd</span><span class="k">)</span><span class="s2">:/root"</span> quay.io/pypa/manylinux1_x86_64:latest bash
    <span class="nb">cd</span> /root/flac-1.3.2
    ./configure <span class="nv">LDFLAGS</span><span class="o">=</span>-static <span class="c1"># compiler flags to make a static build
</span>    make
<span class="nb">exit</span>
cp flac-1.3.2/src/flac/flac ../speech_recognition/flac-linux-x86_64 <span class="o">&amp;&amp;</span> sudo rm -r flac-1.3.2/
</pre> 
        <p>The included <tt><span class="pre">flac-mac</span></tt> executable is extracted from <a href="http://xact.scottcbrown.org/" rel="nofollow">xACT 2.39</a>, which is a frontend for FLAC 1.3.2 that conveniently includes binaries for all of its encoders. Specifically, it is a copy of <tt>xACT 2.39/xACT.app/Contents/Resources/flac</tt> in <tt>xACT2.39.zip</tt>.</p> 
       </div> 
      </div> 
      <div id="authors"> 
       <h2>Authors</h2> 
       <pre>Uberi &lt;azhang9@gmail.com&gt; (Anthony Zhang)
bobsayshilol
arvindch &lt;achembarpu@gmail.com&gt; (Arvind Chembarpu)
kevinismith &lt;kevin_i_smith@yahoo.com&gt; (Kevin Smith)
haas85
DelightRun &lt;changxu.mail@gmail.com&gt;
maverickagm
kamushadenes &lt;kamushadenes@hyadesinc.com&gt; (Kamus Hadenes)
sbraden &lt;braden.sarah@gmail.com&gt; (Sarah Braden)
tb0hdan (Bohdan Turkynewych)
Thynix &lt;steve@asksteved.com&gt; (Steve Dougherty)
</pre> 
       <p>Please report bugs and suggestions at the <a href="https://github.com/Uberi/speech_recognition/issues" rel="nofollow">issue tracker</a>!</p> 
       <p>How to cite this library (APA style):</p> 
       <blockquote>
         Zhang, A. (2017). Speech Recognition (Version 3.7) [Software]. Available from 
        <a href="https://github.com/Uberi/speech_recognition#readme" rel="nofollow">https://github.com/Uberi/speech_recognition#readme</a>.
       </blockquote> 
       <p>How to cite this library (Chicago style):</p> 
       <blockquote>
         Zhang, Anthony. 2017. 
        <em>Speech Recognition</em> (version 3.7).
       </blockquote> 
       <p>Also check out the <a href="https://github.com/DelightRun/PyBaiduYuyin" rel="nofollow">Python Baidu Yuyin API</a>, which is based on an older version of this project, and adds support for <a href="http://yuyin.baidu.com/" rel="nofollow">Baidu Yuyin</a>. Note that Baidu Yuyin is only available inside China.</p> 
      </div> 
      <div id="license"> 
       <h2>License</h2> 
       <p>Copyright 2014-2017 <a href="http://anthony-zhang.me/" rel="nofollow">Anthony Zhang (Uberi)</a>. The source code for this library is available online at <a href="https://github.com/Uberi/speech_recognition" rel="nofollow">GitHub</a>.</p> 
       <p>SpeechRecognition is made available under the 3-clause BSD license. See <tt>LICENSE.txt</tt> in the project’s <a href="https://github.com/Uberi/speech_recognition" rel="nofollow">root directory</a> for more information.</p> 
       <p>For convenience, all the official distributions of SpeechRecognition already include a copy of the necessary copyright notices and licenses. In your project, you can simply <strong>say that licensing information for SpeechRecognition can be found within the SpeechRecognition README, and make sure SpeechRecognition is visible to users if they wish to see it</strong>.</p> 
       <p>SpeechRecognition distributes source code, binaries, and language files from <a href="http://cmusphinx.sourceforge.net/" rel="nofollow">CMU Sphinx</a>. These files are BSD-licensed and redistributable as long as copyright notices are correctly retained. See <tt><span class="pre">speech_recognition/pocketsphinx-data/*/LICENSE*.txt</span></tt> and <tt><span class="pre">third-party/LICENSE-Sphinx.txt</span></tt> for license details for individual parts.</p> 
       <p>SpeechRecognition distributes source code and binaries from <a href="http://people.csail.mit.edu/hubert/pyaudio/" rel="nofollow">PyAudio</a>. These files are MIT-licensed and redistributable as long as copyright notices are correctly retained. See <tt><span class="pre">third-party/LICENSE-PyAudio.txt</span></tt> for license details.</p> 
       <p>SpeechRecognition distributes binaries from <a href="https://xiph.org/flac/" rel="nofollow">FLAC</a> - <tt><span class="pre">speech_recognition/flac-win32.exe</span></tt>, <tt><span class="pre">speech_recognition/flac-linux-x86</span></tt>, and <tt><span class="pre">speech_recognition/flac-mac</span></tt>. These files are GPLv2-licensed and redistributable, as long as the terms of the GPL are satisfied. The FLAC binaries are an <a href="https://www.gnu.org/licenses/gpl-faq.html#MereAggregation" rel="nofollow">aggregate</a> of <a href="https://www.gnu.org/licenses/gpl-faq.html#NFUseGPLPlugins" rel="nofollow">separate programs</a>, so these GPL restrictions do not apply to the library or your programs that use the library, only to FLAC itself. See <tt><span class="pre">LICENSE-FLAC.txt</span></tt> for license details.</p> 
      </div> 
      <a name="downloads">&nbsp;</a> 
      <table class="list" style="margin-bottom: 10px;"> 
       <tbody>
        <tr> 
         <th>File</th> 
         <th>Type</th> 
         <th>Py Version</th> 
         <th>Uploaded on</th> 
         <th style="text-align: right;">Size</th> 
        </tr> 
        <tr class="odd"> 
         <td> <span style="white-space: nowrap;"> <a href="https://pypi.python.org/packages/aa/99/18926cba2e18453756a90332d871541a26f8f9e81dbfc4bed0e7d3ffbf04/SpeechRecognition-3.7.1-py2.py3-none-any.whl#md5=83a0a5fdad23a990fb334fe0257abf4d">SpeechRecognition-3.7.1-py2.py3-none-any.whl</a> (<a title="MD5 Digest" href="/pypi?:action=show_md5&amp;digest=83a0a5fdad23a990fb334fe0257abf4d">md5</a>, <a title="PGP Signature" href="https://pypi.python.org/packages/aa/99/18926cba2e18453756a90332d871541a26f8f9e81dbfc4bed0e7d3ffbf04/SpeechRecognition-3.7.1-py2.py3-none-any.whl.asc">pgp</a>) </span> </td> 
         <td style="white-space: nowrap;"> Python Wheel </td> 
         <td> 3.5 </td> 
         <td>2017-06-27</td> 
         <td style="text-align: right;">31MB</td> 
        </tr> 
        <tr>
         <td id="last" colspan="6"></td>
        </tr> 
       </tbody>
      </table> 
      <ul class="nodot"> 
       <li> <strong>Author:</strong> <span>Anthony Zhang (Uberi)</span> </li> 
       <!-- The <th> elements below are a terrible terrible hack for setuptools --> 
       <li> <strong>Home Page:</strong> 
        <!-- <th>Home Page --> <a href="https://github.com/Uberi/speech_recognition#readme">https://github.com/Uberi/speech_recognition#readme</a> </li> 
       <li> <strong>Bug Tracker:</strong> <a href="https://github.com/Uberi/speech_recognition/issues">https://github.com/Uberi/speech_recognition/issues</a> </li> 
       <li> <strong>Keywords:</strong> <span>speech recognition voice sphinx google wit bing api houndify ibm</span> </li> 
       <li> <strong>License:</strong> <span>BSD</span> </li> 
       <!-- TODO: add link to products in follow dependencies... --> 
       <li> <strong>Categories</strong> 
        <ul class="nodot"> 
         <li> <a href="/pypi?:action=browse&amp;c=5">Development Status :: 5 - Production/Stable</a> </li> 
         <li> <a href="/pypi?:action=browse&amp;c=30">Intended Audience :: Developers</a> </li> 
         <li> <a href="/pypi?:action=browse&amp;c=60">License :: OSI Approved :: BSD License</a> </li> 
         <li> <a href="/pypi?:action=browse&amp;c=104">Natural Language :: English</a> </li> 
         <li> <a href="/pypi?:action=browse&amp;c=147">Operating System :: MacOS :: MacOS X</a> </li> 
         <li> <a href="/pypi?:action=browse&amp;c=150">Operating System :: Microsoft :: Windows</a> </li> 
         <li> <a href="/pypi?:action=browse&amp;c=157">Operating System :: Other OS</a> </li> 
         <li> <a href="/pypi?:action=browse&amp;c=170">Operating System :: POSIX :: Linux</a> </li> 
         <li> <a href="/pypi?:action=browse&amp;c=214">Programming Language :: Python</a> </li> 
         <li> <a href="/pypi?:action=browse&amp;c=527">Programming Language :: Python :: 2</a> </li> 
         <li> <a href="/pypi?:action=browse&amp;c=532">Programming Language :: Python :: 2.7</a> </li> 
         <li> <a href="/pypi?:action=browse&amp;c=533">Programming Language :: Python :: 3</a> </li> 
         <li> <a href="/pypi?:action=browse&amp;c=566">Programming Language :: Python :: 3.3</a> </li> 
         <li> <a href="/pypi?:action=browse&amp;c=587">Programming Language :: Python :: 3.4</a> </li> 
         <li> <a href="/pypi?:action=browse&amp;c=607">Programming Language :: Python :: 3.5</a> </li> 
         <li> <a href="/pypi?:action=browse&amp;c=611">Programming Language :: Python :: 3.6</a> </li> 
         <li> <a href="/pypi?:action=browse&amp;c=366">Topic :: Multimedia :: Sound/Audio :: Speech</a> </li> 
         <li> <a href="/pypi?:action=browse&amp;c=423">Topic :: Software Development :: Libraries :: Python Modules</a> </li> 
        </ul> </li> 
       <li> <strong>Package Index Owner:</strong> <span>Anthony.Zhang</span> </li> 
       <li> <strong><a href="https://github.com/edumbill/doap/wiki">DOAP</a> record:</strong> <a href="/pypi?:action=doap&amp;name=SpeechRecognition&amp;version=3.7.1">SpeechRecognition-3.7.1.xml</a> </li> 
      </ul> 
     </div> 
    </div> 
    <div id="footer"> 
     <div id="credits"> 
      <div style="float: left; margin-right: 1em;" id="badges"> 
       <img src="https://img.shields.io/badge/ipv6-go!-green.svg" alt="ipv6 ready" title="ipv6 ready" border="0">
       <br> 
       <img src="https://img.shields.io/badge/http2-go!-green.svg" alt="http2 ready" title="http2 ready" border="0">
       <br> 
       <img src="/static/images/PythonPoweredAnimSmall.gif" alt="darn right it is" title="Python Powered" border="0"> 
      </div> 
      <div style="float: right" id="donations"> 
       <a href="http://www.python.org/about/website">Website maintained by the Python community</a>
       <br> 
       <a href="https://www.fastly.com/" title="Real-time CDN services provided by Fastly">Real-time CDN by Fastly</a> / 
       <a href="http://developer.rackspace.com/" title="Server hosting by Rackspace Open Source support">Hosting by Rackspace</a>
       <br> 
       <a href="https://aws.amazon.com/s3/" title="Object storage provided by Amazon S3">Object storage by Amazon S3</a> / 
       <a href="http://www.timparkin.co.uk/" title="Design by Tim Parkin, Yorkshire man, photographer and developer">Design by Tim Parkin</a> 
      </div> 
     </div> Copyright © 1990-2017, 
     <a href="http://www.python.org/psf">Python Software Foundation</a>
     <br> 
     <a href="https://pypi.org/policy/terms-of-use/">Terms of Use</a> 
    </div> 
   </div> 
  </div> 
  <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

        ga('create', 'UA-55961911-1', 'auto');
        ga('require', 'linkid', 'linkid.js');
        ga('send', 'pageview');
      </script> 
  <script type="text/javascript" src="//statuspage-production.s3.amazonaws.com/se-v2.js">
      </script> 
  <script type="text/javascript">
        var sp = new StatusPage.page({ page : '2p66nmmycsj3' });
        sp.summary({
          // <![CDATA[
          success: function(data) {
            var div = document.getElementById('statusdiv');
            var reports = "</br><h4 id='statusbox'>Status</h4>\n";
            var outage = 0;
            var maintenance = 0;
            for (i in data.incidents) {
              var incident = data.incidents[i];
              var message, status = incident.status;
              if (status === 'scheduled') {
                message = '<li><a href="' + incident.shortlink + '">' + incident.name + ' scheduled.</a></li>\n';
                reports += message;
                maintenance += 1;
              } else if (status === 'in_progress') {
                message = '<li><a href="' + incident.shortlink + '">' + incident.name + ' is currently in progress.' + '</a></li>\n';
                reports += message;
                maintenance += 1;
              } else if (status !== 'resolved' && status !== 'postmortem' && status !== 'completed') {
                message = '<li><a href="' + incident.shortlink + '">' + incident.name + ': ' + incident.status + '</a></li>\n';
                reports += message;
                outage += 1;
              }
            }
            for (i in data.scheduled_maintenances) {
              var incident = data.scheduled_maintenances[i];
              var message, status = incident.status;
              if (status === 'scheduled') {
                message = '<li><a href="' + incident.shortlink + '">' + incident.name + ' scheduled.</a></li>\n';
                reports += message;
                maintenance += 1;
              } else if (status === 'in_progress') {
                message = '<li><a href="' + incident.shortlink + '">' + incident.name + ' is currently in progress.' + '</a></li>\n';
                reports += message;
                maintenance += 1;
              } else if (status !== 'resolved' && status !== 'postmortem' && status !== 'completed') {
                message = '<li><a href="' + incident.shortlink + '">' + incident.name + ': ' + incident.status + '</a></li>\n';
                reports += message;
                outage += 1;
              }
            }
            if (outage + maintenance === 0) {
              reports += "<li><a href='http://status.python.org'>Nothing to report</a></li>";
            }
            div.innerHTML=reports;
            if (outage > 0) {
              var statusbox = document.getElementById("statusbox");
              statusbox.style.background = '#FC234A';
            }
          }
          // ]]>
        });
      </script>   
 </body>
</html>