<!doctype html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us">
 <head> 
  <link href="http://gmpg.org/xfn/11" rel="profile"> 
  <meta http-equiv="X-UA-Compatible" content="IE=edge"> 
  <meta http-equiv="content-type" content="text/html; charset=utf-8"> 
  <!-- Enable responsiveness on mobile devices--> 
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1"> 
  <title>
    
      Scraping with Python Selenium and PhantomJS · Todd Hayton
    
  </title> 
  <!-- CSS --> 
  <link rel="stylesheet" href="/public/css/poole.css"> 
  <link rel="stylesheet" href="/public/css/syntax.css"> 
  <link rel="stylesheet" href="/public/css/hyde.css"> 
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface"> 
  <!-- Icons --> 
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-144-precomposed.png"> 
  <link rel="shortcut icon" href="/public/favicon.ico"> 
  <!-- RSS --> 
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml"> 
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-27906848-2', 'auto');
    ga('send', 'pageview');
  </script> 
 </head> 
 <body> 
  <div class="sidebar"> 
   <div class="container sidebar-sticky"> 
    <div class="sidebar-about"> 
     <h1> <a href="/"> Todd Hayton </a> </h1> 
     <p class="lead">Freelance Software Developer</p> 
    </div> 
    <nav class="sidebar-nav"> 
     <a class="sidebar-nav-item" href="/">Home</a> 
     <a class="sidebar-nav-item" href="/about/">About</a> 
     <a class="sidebar-nav-item" href="/contact/">Contact</a> 
    </nav> 
    <p>© 2016. All rights reserved.</p> 
   </div> 
  </div> 
  <div class="content container"> 
   <div class="post"> 
    <h1 class="post-title">Scraping with Python Selenium and PhantomJS</h1> 
    <span class="post-date">03 Feb 2015</span> 
    <p>In previous posts, I covered scraping using mechanize as the browser. Sometimes though a site uses so much Javascript to dynamically render its pages that using a tool like mechanize (which can't handle Javascript) isn't really feasable. For these cases, we have to use a browser that can run the Javascript required to generate the pages. </p> 
    <h2>Overview</h2> 
    <p><a href="http://phantomjs.org/">PhantomJS</a> is a headless (non-gui) browser. <a href="http://www.seleniumhq.org/">Selenium</a> is a tool for automating browsers. In this post, we'll use the two together to scrape a Javascript heavy site. First we'll navigate to the site and then, after the HTML has been dynamically generated, we'll feed it into BeautifulSoup for parsing.</p> 
    <p>First let's set up our environment by installing PhantomJS along with the Selenium bindings for Python:</p> 
    <div class="highlight">
     <pre><code class="language-bash" data-lang="bash"><span class="nv">$ </span>mkdir scraper <span class="o">&amp;&amp;</span> <span class="nb">cd </span>scraper
<span class="nv">$ </span>brew install phantomjs
<span class="nv">$ </span>virtualenv venv
<span class="nv">$ </span><span class="nb">source </span>venv/bin/activate
<span class="nv">$ </span>pip install selenium</code></pre>
    </div> 
    <p>Now, let's look at the site we'll use for our example, the job search page for the company <a href="http://www.l-3com.com/careers/us-job-search.html">L-3 Klein Associates</a>. They use the Taleo Applicant Tracking System and the pages are almost entirely generated via Javascript:</p> 
    <p><a href="https://l3com.taleo.net/careersection/l3_ext_us/jobsearch.ftl">https://l3com.taleo.net/careersection/l3_ext_us/jobsearch.ftl</a></p> 
    <p>In this post, we'll develop a script that can scrape, and then print out, all of the jobs listed on their Applicant Tracking System. </p> 
    <p>Let's get started. </p> 
    <h2>Implementation</h2> 
    <p>First, let's sketch out our class, <code>TaleoJobScraper</code>. In the constructor we'll instantiate a webdriver for PhantomJS. Our main method will be <code>scrape()</code>. It will call <code>scrape_job_links()</code> to iterate through the job listings, and then call <code>driver.quit()</code> once it's complete.</p> 
    <div class="highlight">
     <pre><code class="language-python" data-lang="python"><span class="c">#!/usr/bin/env python</span>

<span class="kn">import</span> <span class="nn">re</span><span class="o">,</span> <span class="nn">urlparse</span>

<span class="kn">from</span> <span class="nn">selenium</span> <span class="kn">import</span> <span class="n">webdriver</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">from</span> <span class="nn">time</span> <span class="kn">import</span> <span class="n">sleep</span>

<span class="n">link</span> <span class="o">=</span> <span class="s">'https://l3com.taleo.net/careersection/l3_ext_us/jobsearch.ftl'</span>

<span class="k">class</span> <span class="nc">TaleoJobScraper</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">driver</span> <span class="o">=</span> <span class="n">webdriver</span><span class="o">.</span><span class="n">PhantomJS</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">set_window_size</span><span class="p">(</span><span class="mi">1120</span><span class="p">,</span> <span class="mi">550</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">scrape</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">jobs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">scrape_job_links</span><span class="p">()</span>
        <span class="k">for</span> <span class="n">job</span> <span class="ow">in</span> <span class="n">jobs</span><span class="p">:</span>
            <span class="k">print</span> <span class="n">job</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">quit</span><span class="p">()</span>

<span class="k">if</span> <span class="n">__name__</span> <span class="o">==</span> <span class="s">'__main__'</span><span class="p">:</span>
    <span class="n">scraper</span> <span class="o">=</span> <span class="n">TaleoJobScraper</span><span class="p">()</span>
    <span class="n">scraper</span><span class="o">.</span><span class="n">scrape</span><span class="p">()</span></code></pre>
    </div> 
    <p>Now let's take a look at the <code>scrape_job_links()</code> method, which is listed next:</p> 
    <div class="highlight">
     <pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">scrape_job_links</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">link</span><span class="p">)</span>

    <span class="n">jobs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">pageno</span> <span class="o">=</span> <span class="mi">2</span>

    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">s</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">page_source</span><span class="p">)</span>
        <span class="n">r</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="s">r'jobdetail\.ftl\?job=\d+$'</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">s</span><span class="o">.</span><span class="n">findAll</span><span class="p">(</span><span class="s">'a'</span><span class="p">,</span> <span class="n">href</span><span class="o">=</span><span class="n">r</span><span class="p">):</span>
            <span class="n">tr</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">findParent</span><span class="p">(</span><span class="s">'tr'</span><span class="p">)</span>
            <span class="n">td</span> <span class="o">=</span> <span class="n">tr</span><span class="o">.</span><span class="n">findAll</span><span class="p">(</span><span class="s">'td'</span><span class="p">)</span>

            <span class="n">job</span> <span class="o">=</span> <span class="p">{}</span>
            <span class="n">job</span><span class="p">[</span><span class="s">'title'</span><span class="p">]</span> <span class="o">=</span> <span class="n">a</span><span class="o">.</span><span class="n">text</span>
            <span class="n">job</span><span class="p">[</span><span class="s">'url'</span><span class="p">]</span> <span class="o">=</span> <span class="n">urlparse</span><span class="o">.</span><span class="n">urljoin</span><span class="p">(</span><span class="n">link</span><span class="p">,</span> <span class="n">a</span><span class="p">[</span><span class="s">'href'</span><span class="p">])</span>
            <span class="n">job</span><span class="p">[</span><span class="s">'location'</span><span class="p">]</span> <span class="o">=</span> <span class="n">td</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">text</span>
            <span class="n">jobs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">job</span><span class="p">)</span>

        <span class="n">next_page_elem</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">find_element_by_id</span><span class="p">(</span><span class="s">'next'</span><span class="p">)</span>
        <span class="n">next_page_link</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">'a'</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s">'</span><span class="si">%d</span><span class="s">'</span> <span class="o">%</span> <span class="n">pageno</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">next_page_link</span><span class="p">:</span>
            <span class="n">next_page_elem</span><span class="o">.</span><span class="n">click</span><span class="p">()</span>
            <span class="n">pageno</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">sleep</span><span class="p">(</span><span class="o">.</span><span class="mi">75</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="k">return</span> <span class="n">jobs</span></code></pre>
    </div> 
    <p>First, we open the page with <code>driver.get()</code>. After <code>get()</code> returns, we feed the rendered HTML in <code>driver.page_source</code> into BeautifulSoup. Then we match against the <code>href</code> attribute of the job links. For each job link we extract the title, url, and location.</p> 
    <p>To get all of the jobs, we also need to handle pagination. There's a pager at the bottom of the jobs listings. Below is a screenshot of the pager. A user can click a page number or the <code>Next</code> link to navigate through the listings.</p> 
    <p><img src="/assets/taleo/pagination.png" alt="Form Image"></p> 
    <p>We use the <code>Next</code> link to iterate through every page of the results by first finding the <code>Next</code> element using the driver's <a href="http://selenium-python.readthedocs.org/en/latest/locating-elements.html">find_element_by_id</a> method and then calling <code>click()</code> if we're not on the last page.</p> 
    <div class="highlight">
     <pre><code class="language-python" data-lang="python"><span class="n">next_page_elem</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">driver</span><span class="o">.</span><span class="n">find_element_by_id</span><span class="p">(</span><span class="s">'next'</span><span class="p">)</span>
<span class="n">next_page_link</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s">'a'</span><span class="p">,</span> <span class="n">text</span><span class="o">=</span><span class="s">'</span><span class="si">%d</span><span class="s">'</span> <span class="o">%</span> <span class="n">pageno</span><span class="p">)</span>

<span class="k">if</span> <span class="n">next_page_link</span><span class="p">:</span>
    <span class="n">next_page_elem</span><span class="o">.</span><span class="n">click</span><span class="p">()</span>
    <span class="n">pageno</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">break</span></code></pre>
    </div> 
    <p>To determine if we're on the last page we search for a link whose text equals the current page number plus one. If no such link exists then we've reached the last page of results and break.</p> 
    <p>If you'd like to see a working version of the code developed in this post, it's available on github <a href="https://github.com/thayton/taleo_job_scraper">here</a>.</p> 
    <h2>Shameless Plug</h2> 
    <p>Have a scraping project you'd like done? I'm available for hire. <a href="/contact">Contact me</a> with some details about your project and I'll give you a quote.</p> 
   </div> 
   <div class="related"> 
    <h2>Related Posts</h2> 
    <ul class="related-posts"> 
     <li> <h3> <a href="/2016/01/04/book-review-web-scraping-with-python/"> Book Review: Web Scraping with Python <small>04 Jan 2016</small> </a> </h3> </li> 
     <li> <h3> <a href="/2015/12/11/iterating-through-dynamic-select-options-with-selenium/"> Iterating through Dynamic Select Options with Selenium <small>11 Dec 2015</small> </a> </h3> </li> 
     <li> <h3> <a href="/2015/05/14/using-selenium-to-scrape-aspnet-pages-with-ajax-pagination/"> Using Selenium to Scrape ASP.NET Pages with AJAX Pagination <small>14 May 2015</small> </a> </h3> </li> 
    </ul> 
   </div> 
  </div>  
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-563a5179a6737d1c" async></script>  
 </body>
</html>